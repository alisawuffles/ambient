{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8825d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/xlab/alisaliu/ambient/notebooks\n",
      "/mmfs1/gscratch/xlab/alisaliu/ambient\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'ambient':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ada9fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mturk.annotation_utils import read_batch, time_format, clean_validation_batch\n",
    "from collections import defaultdict\n",
    "from utils.constants import id2label, NLI_LABELS\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4473b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = read_batch(369686)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc15738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A14KPHOYAQCFWH    50\n",
       "A3AA2VKV87R6PG    50\n",
       "A1KBELVHWNE4D5    50\n",
       "A2AX828Q4WXK3Z    50\n",
       "Name: worker_id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Zhaofeng: A2AX828Q4WXK3Z\n",
    "Julian: A3AA2VKV87R6PG\n",
    "Alane: A14KPHOYAQCFWH\n",
    "Alisa: A1KBELVHWNE4D5\n",
    "'''\n",
    "\n",
    "batch_df.worker_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3314f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i, example_df in batch_df.groupby('id'):\n",
    "    dummy_row = example_df.iloc[0]\n",
    "    premise, hypothesis = dummy_row['premise'], dummy_row['hypothesis']\n",
    "    annotations = example_df.q0_gold.tolist()\n",
    "    results.append({\n",
    "        'premise': premise,\n",
    "        'hypothesis': hypothesis,\n",
    "        'annotations': annotations\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f37f1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_json('annotation/validation/batches/batch_369686/annotations.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beb4520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_examples = []\n",
    "for i, example_df in batch_df.groupby('id'):\n",
    "    dummy_row = example_df.iloc[0]\n",
    "    annotations = example_df['q0_gold'].tolist()\n",
    "    rewrites = defaultdict(list)\n",
    "    for _, row in example_df.iterrows():\n",
    "        for i in range(1, 5):\n",
    "            if f'q{i}_gold' in row and row[f'q{i}_gold'] != 'nan':\n",
    "                label = row[f'q{i}_gold']\n",
    "                rewrites[label].append({\n",
    "                    'premise': row[f'premise{i}'],\n",
    "                    'hypothesis': row[f'hypothesis{i}']\n",
    "                })\n",
    "    processed_examples.append({\n",
    "        'premise': dummy_row['premise'],\n",
    "        'hypothesis': dummy_row['hypothesis'],\n",
    "        'annotations': annotations,\n",
    "        'rewrites': rewrites,\n",
    "        'comments': example_df['feedback'].tolist()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9feb5271",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(processed_examples).to_json('annotation/validation/batches/batch_369686/annotations.json', indent=2, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d159cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = pd.DataFrame(processed_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c52be5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biggest_annotation(annotations):\n",
    "    \"\"\"\n",
    "    get annotation with the most labels\n",
    "    \"\"\"\n",
    "    def get_length(annotation):\n",
    "        return len(annotation.split('|'))\n",
    "\n",
    "    biggest_annotation = ''\n",
    "    for annot in annotations:\n",
    "        if get_length(annot) > get_length(biggest_annotation):\n",
    "            biggest_annotation = annot\n",
    "    return biggest_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "232c5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match_ct = 0\n",
    "union_ct = 0\n",
    "tot = 0\n",
    "discards = 0\n",
    "discards_individual = 0\n",
    "annotations = []\n",
    "\n",
    "for i, row in processed_df.iterrows():\n",
    "    if 'discard' in row['annotations']:\n",
    "        discards_individual += row['annotations'].count('discard')\n",
    "        discards += 1\n",
    "        continue\n",
    "    tot += 1\n",
    "    annotations.append(row['annotations'])\n",
    "    unique_annotations = set(row['annotations']).difference({'discard'})\n",
    "    labels_union = set('|'.join(unique_annotations).split('|'))\n",
    "    biggest_label = get_biggest_annotation(unique_annotations)\n",
    "    if len(unique_annotations) == 1:\n",
    "        exact_match_ct += 1\n",
    "    if labels_union.issubset(set(biggest_label.split('|'))):\n",
    "        union_ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd60b2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6486486486486487"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_ct/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e95e06ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40540540540540543"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match_ct/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20046865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.419607843137255"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = aggregate_raters(annotations)[0]\n",
    "fleiss_kappa(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a343b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_annotations = {}\n",
    "for label in NLI_LABELS:\n",
    "    label_annotations = []\n",
    "    for ex_annotations in annotations:\n",
    "        ex_annotation = []\n",
    "        for annotation in ex_annotations:\n",
    "            if label in annotation:\n",
    "                ex_annotation.append(1)\n",
    "            else:\n",
    "                ex_annotation.append(0)\n",
    "        label_annotations.append(ex_annotation)\n",
    "    binary_annotations[label] = label_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "239c8980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contradiction: 0.6170312867560573\n",
      "entailment: 0.645402815214136\n",
      "neutral: 0.44206349206349227\n"
     ]
    }
   ],
   "source": [
    "for label in NLI_LABELS:\n",
    "    arr = aggregate_raters(binary_annotations[label])[0]\n",
    "    print(f'{label}: {fleiss_kappa(arr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a786e49b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
