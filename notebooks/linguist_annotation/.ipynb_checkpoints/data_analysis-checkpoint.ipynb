{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af6de4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/xlab/alisaliu/ambient/notebooks\n",
      "/mmfs1/gscratch/xlab/alisaliu/ambient\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "analyze final dataset\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'ambient':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8c7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.constants import NLI_LABELS\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48d4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df = pd.read_json('AmbiEnt/cleaned_examples.jsonl', lines=True)\n",
    "validated_df = pd.read_json('AmbiEnt/linguist_annotations.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0159474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = validated_df.merge(annotated_df[['id', 'annotations']], on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaa24aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_multilabel_output(labels):\n",
    "    o = []\n",
    "    for label in NLI_LABELS:\n",
    "        if label in labels:\n",
    "            o.append(1)\n",
    "        else:\n",
    "            o.append(0)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce931d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on average, how well do the two annotators cover the final set of labels?\n",
    "merge_df = merge_df.loc[~merge_df['annotations'].isna()]\n",
    "coverage, union_coverage = [], []\n",
    "f1 = 0\n",
    "acc = 0\n",
    "for i, row in merge_df.iterrows():\n",
    "    gold = set(row['labels'].split(', '))\n",
    "    union_a = set()\n",
    "    for annotation in row['annotations']:\n",
    "        a = set(annotation.split('|'))\n",
    "        union_a = union_a.union(a)\n",
    "        if len(gold) > 1:\n",
    "            c = len(a.intersection(gold))/len(gold)\n",
    "            coverage.append(c)\n",
    "        f1 += f1_score(format_multilabel_output(gold), format_multilabel_output(a))\n",
    "        if gold == a:\n",
    "            acc += 1\n",
    "    c = len(union_a.intersection(gold))/len(gold)\n",
    "    union_coverage.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7e3c5ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6785310734463277"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "625a7dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9490771625528129"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(union_coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f360a693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7744289199379047"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# macro F1? this might be wrong lol\n",
    "f1/(2*len(validated_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fdee7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.564870259481038"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc/(2*len(validated_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c0a3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inter-annotator agreement\n",
    "acc, f1, subset_acc = 0, 0, 0\n",
    "for i, row in merge_df.iterrows():\n",
    "    a1 = set(row['annotations'][0].split('|'))\n",
    "    a2 = set(row['annotations'][1].split('|'))\n",
    "    if a1 == a2:\n",
    "        acc += 1\n",
    "    if a1.issubset(a2) or a2.issubset(a1):\n",
    "        subset_acc += 1\n",
    "    f1 += f1_score(format_multilabel_output(a1), format_multilabel_output(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73e5f161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42115768463073855"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc/len(validated_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdf941c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7618097139055223"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_acc/len(validated_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56e7fa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6647815480150758"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1/len(validated_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71fb6ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for examples where both annotators give a single label, how often is the validated label set just the union of those two labels?\n",
    "union = 0\n",
    "tot = 0\n",
    "l = []\n",
    "for i, row in merge_df.iterrows():\n",
    "    a1 = set(row['annotations'][0].split('|'))\n",
    "    a2 = set(row['annotations'][1].split('|'))\n",
    "    gold = set(row['labels'].split(', '))\n",
    "    if len(a1) == 1 and len(a2) == 1 and a1 != a2:\n",
    "        l.append((a1, a2, gold))\n",
    "        if a1.union(a2).issubset(gold):\n",
    "            union += 1\n",
    "        tot += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4441fabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26582278481012656"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union/tot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
