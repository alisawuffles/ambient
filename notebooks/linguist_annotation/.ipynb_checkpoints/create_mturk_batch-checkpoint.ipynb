{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbfc6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/xlab/alisaliu/ambignli/notebooks\n",
      "/mmfs1/gscratch/xlab/alisaliu/ambignli\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'ambignli':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fbbe8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from modeling.multitask_model import RobertaForMultitaskSequenceClassification\n",
    "from utils.utils import predict_nli\n",
    "from utils.mturk_utils import read_batch\n",
    "from torch import sigmoid\n",
    "from collections import Counter\n",
    "from utils.utils import ensure_dir\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93160b6",
   "metadata": {},
   "source": [
    "## find possibly ambiguous examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ec577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nli(premise, hypothesis, model, tokenizer):\n",
    "    x = tokenizer(premise, hypothesis, return_tensors='pt', max_length=128, truncation=True).to('cuda')\n",
    "    logits = model(**x).logits\n",
    "    # multi-task model\n",
    "    if hasattr(model, 'output_heads'):\n",
    "        probs = logits.softmax(dim=-1).squeeze(0)\n",
    "        return {model.config.id2label[i]: probs[i,1].item() for i in range(len(probs))}\n",
    "    # multi-label model\n",
    "    elif model.config.problem_type == 'multi_label_classification':\n",
    "        logits = logits.squeeze(0)\n",
    "        probs = sigmoid(logits)\n",
    "        return {model.config.id2label[i]: probs[i].item() for i in range(len(probs))}\n",
    "    # classification model\n",
    "    else:\n",
    "        probs = logits.softmax(dim=1).squeeze(0)\n",
    "        return {model.config.id2label[i]: probs[i].item() for i in range(len(probs))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df1490bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_model = RobertaForSequenceClassification.from_pretrained('models/roberta-large-wanli-multilabel').to('cuda')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('models/roberta-large-wanli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca847de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_example_ambiguity(df):\n",
    "    df['ambiguity_score'] = None\n",
    "    df['predicted_labels'] = None\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df.index)):\n",
    "        premise, hypothesis = row['premise'], row['hypothesis']\n",
    "        probs = predict_nli(premise, hypothesis, multilabel_model, tokenizer)\n",
    "        preds = set([l for l, p in probs.items() if p > 0.04])\n",
    "        # ambiguity score is the probability assigned to the second-highest label\n",
    "        sorted_probs = sorted([p for p in probs.values()], reverse=True)\n",
    "        s = sorted_probs[1]\n",
    "        df.at[i, 'ambiguity_score'] = s\n",
    "        df.at[i, 'predicted_labels'] = ', '.join(sorted(preds))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921cb583",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dir = Path('generated_data/wanli_disagreement_p0.9_davinci-002')\n",
    "df_wanli_disagreement_instruct = pd.read_json(gen_dir / 'filtered_examples.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ac77a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77564/77564 [18:52<00:00, 68.46it/s]\n"
     ]
    }
   ],
   "source": [
    "df = compute_example_ambiguity(df_wanli_disagreement_instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44964b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>nearest_neighbors</th>\n",
       "      <th>ambiguity_score</th>\n",
       "      <th>predicted_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The proposal was met with some skepticism from...</td>\n",
       "      <td>The proposal was met with some optimism from t...</td>\n",
       "      <td>[82936, 245722, 331487, 19994]</td>\n",
       "      <td>0.925016</td>\n",
       "      <td>contradiction, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The company's decision to downsize was met wit...</td>\n",
       "      <td>The company's decision to downsize was met wit...</td>\n",
       "      <td>[82936, 245722, 331487, 19994]</td>\n",
       "      <td>0.886042</td>\n",
       "      <td>contradiction, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The amount of money that was spent on the proj...</td>\n",
       "      <td>The amount of money that was saved on the proj...</td>\n",
       "      <td>[82936, 245722, 331487, 19994]</td>\n",
       "      <td>0.630185</td>\n",
       "      <td>contradiction, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>We cannot be sure that the meeting will be pro...</td>\n",
       "      <td>We cannot be sure that the meeting will not be...</td>\n",
       "      <td>[82936, 245722, 331487, 19994]</td>\n",
       "      <td>0.126387</td>\n",
       "      <td>contradiction, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The company will only offer the position to so...</td>\n",
       "      <td>The company will only offer the position to so...</td>\n",
       "      <td>[214335, 8249, 65040, 102411]</td>\n",
       "      <td>0.791046</td>\n",
       "      <td>entailment, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77557</th>\n",
       "      <td>104063</td>\n",
       "      <td>Most people in the United States speak English.</td>\n",
       "      <td>English is the official language of the United...</td>\n",
       "      <td>[22805, 173022, 66665, 188215]</td>\n",
       "      <td>0.747514</td>\n",
       "      <td>entailment, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77558</th>\n",
       "      <td>104064</td>\n",
       "      <td>The novel is a fiction.</td>\n",
       "      <td>The movie is based on a true story.</td>\n",
       "      <td>[22805, 173022, 66665, 188215]</td>\n",
       "      <td>0.662432</td>\n",
       "      <td>contradiction, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77559</th>\n",
       "      <td>104065</td>\n",
       "      <td>The poet T.S. Eliot wrote, \"We shall not cease...</td>\n",
       "      <td>We never really know a place until we leave it.</td>\n",
       "      <td>[22805, 173022, 66665, 188215]</td>\n",
       "      <td>0.066416</td>\n",
       "      <td>contradiction, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77561</th>\n",
       "      <td>104067</td>\n",
       "      <td>The researchers say that this is the first stu...</td>\n",
       "      <td>This is the first study to look at the long-te...</td>\n",
       "      <td>[133594, 371112, 155042, 348420]</td>\n",
       "      <td>0.744364</td>\n",
       "      <td>entailment, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77562</th>\n",
       "      <td>104068</td>\n",
       "      <td>In a recent study, researchers found that peop...</td>\n",
       "      <td>Coffee is good for you.</td>\n",
       "      <td>[133594, 371112, 155042, 348420]</td>\n",
       "      <td>0.781466</td>\n",
       "      <td>entailment, neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35818 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                            premise  \\\n",
       "0           0  The proposal was met with some skepticism from...   \n",
       "1           2  The company's decision to downsize was met wit...   \n",
       "2           3  The amount of money that was spent on the proj...   \n",
       "3           4  We cannot be sure that the meeting will be pro...   \n",
       "4           5  The company will only offer the position to so...   \n",
       "...       ...                                                ...   \n",
       "77557  104063    Most people in the United States speak English.   \n",
       "77558  104064                            The novel is a fiction.   \n",
       "77559  104065  The poet T.S. Eliot wrote, \"We shall not cease...   \n",
       "77561  104067  The researchers say that this is the first stu...   \n",
       "77562  104068  In a recent study, researchers found that peop...   \n",
       "\n",
       "                                              hypothesis  \\\n",
       "0      The proposal was met with some optimism from t...   \n",
       "1      The company's decision to downsize was met wit...   \n",
       "2      The amount of money that was saved on the proj...   \n",
       "3      We cannot be sure that the meeting will not be...   \n",
       "4      The company will only offer the position to so...   \n",
       "...                                                  ...   \n",
       "77557  English is the official language of the United...   \n",
       "77558                The movie is based on a true story.   \n",
       "77559    We never really know a place until we leave it.   \n",
       "77561  This is the first study to look at the long-te...   \n",
       "77562                            Coffee is good for you.   \n",
       "\n",
       "                      nearest_neighbors ambiguity_score  \\\n",
       "0        [82936, 245722, 331487, 19994]        0.925016   \n",
       "1        [82936, 245722, 331487, 19994]        0.886042   \n",
       "2        [82936, 245722, 331487, 19994]        0.630185   \n",
       "3        [82936, 245722, 331487, 19994]        0.126387   \n",
       "4         [214335, 8249, 65040, 102411]        0.791046   \n",
       "...                                 ...             ...   \n",
       "77557    [22805, 173022, 66665, 188215]        0.747514   \n",
       "77558    [22805, 173022, 66665, 188215]        0.662432   \n",
       "77559    [22805, 173022, 66665, 188215]        0.066416   \n",
       "77561  [133594, 371112, 155042, 348420]        0.744364   \n",
       "77562  [133594, 371112, 155042, 348420]        0.781466   \n",
       "\n",
       "             predicted_labels  \n",
       "0      contradiction, neutral  \n",
       "1      contradiction, neutral  \n",
       "2      contradiction, neutral  \n",
       "3      contradiction, neutral  \n",
       "4         entailment, neutral  \n",
       "...                       ...  \n",
       "77557     entailment, neutral  \n",
       "77558  contradiction, neutral  \n",
       "77559  contradiction, neutral  \n",
       "77561     entailment, neutral  \n",
       "77562     entailment, neutral  \n",
       "\n",
       "[35818 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thres = 0.05\n",
    "sub_df = df.loc[df['ambiguity_score'] > thres]\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8813643",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_balanced_df = pd.read_json(gen_dir / 'balanced_examples_old.jsonl', lines=True)\n",
    "old_ids = old_balanced_df.id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d78824fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62807/2767759436.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  past_df = sub_df.loc[sub_df['id'].isin(old_ids)][~con_mask][ent_mask]\n",
      "/tmp/ipykernel_62807/2767759436.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  balanced_df = pd.concat([balanced_df, sub_df.loc[~sub_df['id'].isin(old_ids)][~con_mask][ent_mask].sample(num_entailment_needed-len(past_df))])\n"
     ]
    }
   ],
   "source": [
    "# include all examples with contradiction label\n",
    "con_mask = sub_df['predicted_labels'].str.contains('contradiction')\n",
    "balanced_df = sub_df[con_mask]\n",
    "# get label distribution\n",
    "counter = [ls.split(', ') for ls in balanced_df.predicted_labels.tolist()]\n",
    "counter = Counter([l for ls in counter for l in ls])\n",
    "# patch up with entailment examples\n",
    "num_entailment_needed = counter['contradiction'] - counter['entailment']\n",
    "ent_mask = sub_df['predicted_labels'].str.contains('entailment')\n",
    "# balanced_df = pd.concat([balanced_df, sub_df[~con_mask][ent_mask].sample(num_entailment_needed)])\n",
    "# use examples from previous data\n",
    "past_df = sub_df.loc[sub_df['id'].isin(old_ids)][~con_mask][ent_mask]\n",
    "balanced_df = pd.concat([balanced_df, past_df])\n",
    "balanced_df = pd.concat([balanced_df, sub_df.loc[~sub_df['id'].isin(old_ids)][~con_mask][ent_mask].sample(num_entailment_needed-len(past_df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8e400a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contradiction, neutral                6850\n",
       "entailment, neutral                   6850\n",
       "contradiction, entailment, neutral    2531\n",
       "contradiction, entailment              595\n",
       "Name: predicted_labels, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.predicted_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40243e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16812\n",
      "16951\n",
      "16826\n"
     ]
    }
   ],
   "source": [
    "print(len(set(balanced_df.id.tolist()).intersection(set(old_ids))))\n",
    "print(len(set(old_ids)))\n",
    "print(len(balanced_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a552c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.sample(frac=1).to_csv('annotation/ambignli/balanced_examples.csv', index=False)\n",
    "balanced_df.sample(frac=1).to_json(gen_dir / 'balanced_examples.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6143aae",
   "metadata": {},
   "source": [
    "## pre-create a bunch of new-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecda64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = pd.read_csv('annotation/ambignli/balanced_examples.csv')\n",
    "annotated_ids = pd.read_json('annotation/ambignli/annotated_examples.jsonl', lines=True)['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a3d6e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15002\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "remaining_pool_df = balanced_df[~balanced_df.id.isin(annotated_ids)]\n",
    "print(len(remaining_pool_df))\n",
    "ensure_dir('annotation/batches/nextbatches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2836e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch_df in enumerate(np.array_split(remaining_pool_df, 15030//100)):\n",
    "    batch_df.to_csv(f'annotation/batches/nextbatches/examples_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1869e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_dir = Path('annotation/batches')\n",
    "dirs = [d for d in os.listdir(batches_dir) if (os.path.isdir(batches_dir / d) and d.startswith('batch_'))]\n",
    "batch_dfs = []\n",
    "\n",
    "for batch_dir in dirs:\n",
    "    batch_id = int(batch_dir.split('_')[-1])\n",
    "    batch_df = pd.read_csv(batches_dir / batch_dir / f'Batch_{batch_id}_batch_results.csv')\n",
    "    batch_dfs.append(batch_df)\n",
    "\n",
    "annotations_df = pd.concat(batch_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de59b5bb",
   "metadata": {},
   "source": [
    "## create batches for singly labeled examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5545e6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>worker_ids</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>annotations</th>\n",
       "      <th>disambiguations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[A3FVGZKEEKXBON, A15WACUALQNT90]</td>\n",
       "      <td>We cannot be sure that the meeting will be pro...</td>\n",
       "      <td>We cannot be sure that the meeting will not be...</td>\n",
       "      <td>[entailment|neutral, entailment]</td>\n",
       "      <td>{'neutral': [{'premise': 'We cannot be sure th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>[A362GR9VFKI1V4, A15WACUALQNT90]</td>\n",
       "      <td>The person who told me the story is an unrelia...</td>\n",
       "      <td>I can't believe the story because the person w...</td>\n",
       "      <td>[entailment, neutral]</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>[AZ1568AZA22GD]</td>\n",
       "      <td>The theme of the conference is 'Empowering You...</td>\n",
       "      <td>The conference is about empowering young girls.</td>\n",
       "      <td>[entailment]</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                        worker_ids  \\\n",
       "0   4  [A3FVGZKEEKXBON, A15WACUALQNT90]   \n",
       "1  39  [A362GR9VFKI1V4, A15WACUALQNT90]   \n",
       "2  75                   [AZ1568AZA22GD]   \n",
       "\n",
       "                                             premise  \\\n",
       "0  We cannot be sure that the meeting will be pro...   \n",
       "1  The person who told me the story is an unrelia...   \n",
       "2  The theme of the conference is 'Empowering You...   \n",
       "\n",
       "                                          hypothesis  \\\n",
       "0  We cannot be sure that the meeting will not be...   \n",
       "1  I can't believe the story because the person w...   \n",
       "2    The conference is about empowering young girls.   \n",
       "\n",
       "                        annotations  \\\n",
       "0  [entailment|neutral, entailment]   \n",
       "1             [entailment, neutral]   \n",
       "2                      [entailment]   \n",
       "\n",
       "                                     disambiguations  \n",
       "0  {'neutral': [{'premise': 'We cannot be sure th...  \n",
       "1                                                 {}  \n",
       "2                                                 {}  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_df = pd.read_json('annotation/ambignli/cleaned_examples.jsonl', lines=True)\n",
    "annotated_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e776e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 576 singly-labeled examples, out of a total of 2017 annotated examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57549/2603546019.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single_df['worker_id'] = [l[0] for l in single_df['worker_ids']]\n",
      "/gscratch/cse/alisaliu/miniconda3/envs/nli/lib/python3.9/site-packages/pandas/core/frame.py:4901: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>annotations</th>\n",
       "      <th>disambiguations</th>\n",
       "      <th>worker_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>The theme of the conference is 'Empowering You...</td>\n",
       "      <td>The conference is about empowering young girls.</td>\n",
       "      <td>[entailment]</td>\n",
       "      <td>{}</td>\n",
       "      <td>AZ1568AZA22GD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1070</td>\n",
       "      <td>The company has not yet released a statement.</td>\n",
       "      <td>A company representative declined to comment.</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>{}</td>\n",
       "      <td>A3FVGZKEEKXBON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1388</td>\n",
       "      <td>It's getting harder and harder to find a good ...</td>\n",
       "      <td>I'm not sure if I'll be able to find a good job.</td>\n",
       "      <td>[entailment|neutral]</td>\n",
       "      <td>{'entailment': [{'premise': 'It's getting hard...</td>\n",
       "      <td>A1QW104XQNIICA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            premise  \\\n",
       "2     75  The theme of the conference is 'Empowering You...   \n",
       "20  1070      The company has not yet released a statement.   \n",
       "23  1388  It's getting harder and harder to find a good ...   \n",
       "\n",
       "                                          hypothesis           annotations  \\\n",
       "2    The conference is about empowering young girls.          [entailment]   \n",
       "20     A company representative declined to comment.             [neutral]   \n",
       "23  I'm not sure if I'll be able to find a good job.  [entailment|neutral]   \n",
       "\n",
       "                                      disambiguations       worker_id  \n",
       "2                                                  {}   AZ1568AZA22GD  \n",
       "20                                                 {}  A3FVGZKEEKXBON  \n",
       "23  {'entailment': [{'premise': 'It's getting hard...  A1QW104XQNIICA  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single_annotation(row):\n",
    "    return True if len(row['worker_ids']) == 1 else False\n",
    "\n",
    "single_df = annotated_df[annotated_df.apply(single_annotation, axis=1)]\n",
    "print(f'There are {len(single_df.index)} singly-labeled examples, out of a total of {len(annotated_df.index)} annotated examples')\n",
    "single_df['worker_id'] = [l[0] for l in single_df['worker_ids']]\n",
    "single_df.drop('worker_ids', inplace=True, axis=1)\n",
    "single_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed68582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = pd.read_csv('annotation/ambignli/balanced_examples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cafcb273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples that should be annotated by Emma\n",
    "emma_ids = single_df.loc[single_df['worker_id'] != 'A15WACUALQNT90'].id.tolist()\n",
    "not_emma_ids = single_df.loc[single_df['worker_id'] == 'A15WACUALQNT90'].id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64a7077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.loc[balanced_df['id'].isin(emma_ids)].to_csv('annotation/batches/batch_emma/examples.csv', index=False)\n",
    "balanced_df.loc[balanced_df['id'].isin(enot_emma_ids)].to_csv('annotation/batches/batch_not_emma/examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b910d72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
