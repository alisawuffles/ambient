{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3329b7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/xlab/alisaliu/ambient/notebooks\n",
      "/mmfs1/gscratch/xlab/alisaliu/ambient\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'ambient':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fbf387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80990913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translate(sentence, mt_model, s_tokenizer, t_tokenizer):\n",
    "    inputs = s_tokenizer(sentence, return_tensors=\"pt\", padding=True)\n",
    "    translated_tokens = mt_model.generate(**inputs, forced_bos_token_id=s_tokenizer.lang_code_to_id[\"yor_Latn\"])\n",
    "    outputs = s_tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)\n",
    "    inputs = t_tokenizer(outputs, return_tensors=\"pt\", padding=True)\n",
    "    translated_tokens = mt_model.generate(**inputs, forced_bos_token_id=t_tokenizer.lang_code_to_id[\"eng_Latn\"])\n",
    "    \n",
    "    # if generation is the max length (always due to repetition), then we need to truncate\n",
    "    if len(translated_tokens[0]) == mt_model.config.max_length:\n",
    "        translated_tokens = [translated_tokens[0][:25]]\n",
    "        \n",
    "    paraphrase = t_tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # if the back-translation is equivalent to the original sentence, then decode again with different hyperparameters\n",
    "    if paraphrase == sentence:\n",
    "        translated_tokens = mt_model.generate(\n",
    "            **inputs, \n",
    "            forced_bos_token_id=t_tokenizer.lang_code_to_id[\"eng_Latn\"],\n",
    "            num_beams=5,\n",
    "            do_sample=True,\n",
    "            temperature=2.0,\n",
    "            top_p=1.0,\n",
    "            num_return_sequences=5,\n",
    "        )\n",
    "        beam_paraphrases = set(t_tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)) - set([sentence])\n",
    "        paraphrase = beam_paraphrases[0]\n",
    "        \n",
    "    return paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61e3170e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539\n"
     ]
    }
   ],
   "source": [
    "ambignli = pd.read_json('annotation/AmbiEnt/ambient_combined.jsonl', lines=True)\n",
    "ambiguous_df = ambignli[ambignli['premise_ambiguous'] ^ ambignli['hypothesis_ambiguous']]\n",
    "print(len(ambiguous_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55d53953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining examples for annotation: 2\n"
     ]
    }
   ],
   "source": [
    "batches_dir = Path('annotation/crowdworker_exp/batches')\n",
    "dirs = [d for d in os.listdir(batches_dir) if (os.path.isdir(batches_dir / d) and d.startswith('batch_'))]\n",
    "\n",
    "validated_ids = []\n",
    "for batch_dir in dirs:\n",
    "    ids = pd.read_json(batches_dir / batch_dir / f'batch_results.jsonl', lines=True).id.tolist()\n",
    "    ids = [int(id) if (isinstance(id, str) and id.isdigit()) else id for id in ids]\n",
    "    validated_ids += ids\n",
    "\n",
    "ambiguous_df = ambiguous_df.loc[~ambiguous_df['id'].isin(validated_ids)]\n",
    "print(f'Remaining examples for annotation: {len(ambiguous_df.index)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "496dfd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_file(ambiguous_df, target_lang):\n",
    "    s_tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang='eng_Latn')\n",
    "    t_tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=target_lang)\n",
    "    mt_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "    mturk_examples = []\n",
    "    for i, row in tqdm(ambiguous_df.iterrows(), total=len(ambiguous_df.index)):\n",
    "        ambiguous_sentence_key = 'premise' if row['premise_ambiguous'] else 'hypothesis'\n",
    "        other_sentence_key = 'hypothesis' if row['premise_ambiguous'] else 'premise'\n",
    "        ambiguous_sentence = row[ambiguous_sentence_key]\n",
    "        \n",
    "        disambiguations = [d[ambiguous_sentence_key] for d in row['disambiguations']]\n",
    "        labels = [d['label'] for d in row['disambiguations']]\n",
    "\n",
    "        if len(disambiguations) == 3:\n",
    "            distractor_idx = None\n",
    "        else:\n",
    "            distractor_idx = random.choice(range(3))\n",
    "            distractor_sentence = back_translate([ambiguous_sentence], mt_model, s_tokenizer, t_tokenizer)\n",
    "            disambiguations = disambiguations[:distractor_idx] + [distractor_sentence] + disambiguations[distractor_idx:]\n",
    "            labels = labels[:distractor_idx] + [None] + labels[distractor_idx:]\n",
    "        \n",
    "        if len(disambiguations) != 3:\n",
    "            print(row)\n",
    "            continue\n",
    "        \n",
    "        ex = {\n",
    "            'id': row['id'],\n",
    "            'premise': row['premise'],\n",
    "            'hypothesis': row['hypothesis'],\n",
    "            'ambiguous_sent_html': f'<span class=\"{ambiguous_sentence_key}\">{ambiguous_sentence_key}</span>',\n",
    "            'ambiguous_sent': ambiguous_sentence,\n",
    "            'distractor_idx': distractor_idx,\n",
    "            'labels': labels,\n",
    "        }\n",
    "\n",
    "        for i in range(3):\n",
    "            ex[f'{ambiguous_sentence_key}{i+1}'] = disambiguations[i]\n",
    "            ex[f'{other_sentence_key}{i+1}'] = row[other_sentence_key]\n",
    "            ex[f'interpretation{i+1}'] = disambiguations[i]\n",
    "        \n",
    "        mturk_examples.append(ex)\n",
    "    \n",
    "    example_df = pd.DataFrame(mturk_examples)\n",
    "    example_df = example_df[\n",
    "        ['id', 'premise', 'hypothesis', 'ambiguous_sent_html', 'ambiguous_sent', 'distractor_idx', 'labels'] \n",
    "        + [f'{e}{i+1}' for e in ['premise', 'hypothesis', 'interpretation'] for i in range(3)]\n",
    "    ]\n",
    "    return example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59ae1488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/gscratch/cse/alisaliu/miniconda3/envs/nli/lib/python3.9/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (200) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                                    2_c\n",
      "premise                 My wife will not be coming to the event with m...\n",
      "hypothesis                                    My wife will not be coming.\n",
      "premise_ambiguous                                                    True\n",
      "hypothesis_ambiguous                                                False\n",
      "labels                                 entailment, neutral, contradiction\n",
      "meta                                         {'source': 'quote from Tal'}\n",
      "disambiguations         [{'premise': 'It is not the case that both my ...\n",
      "Name: 2, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>ambiguous_sent_html</th>\n",
       "      <th>ambiguous_sent</th>\n",
       "      <th>distractor_idx</th>\n",
       "      <th>labels</th>\n",
       "      <th>premise1</th>\n",
       "      <th>premise2</th>\n",
       "      <th>premise3</th>\n",
       "      <th>hypothesis1</th>\n",
       "      <th>hypothesis2</th>\n",
       "      <th>hypothesis3</th>\n",
       "      <th>interpretation1</th>\n",
       "      <th>interpretation2</th>\n",
       "      <th>interpretation3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132_c</td>\n",
       "      <td>A woman in this neighborhood gives birth every...</td>\n",
       "      <td>There is a particular woman with a birth rate ...</td>\n",
       "      <td>&lt;span class=\"premise\"&gt;premise&lt;/span&gt;</td>\n",
       "      <td>A woman in this neighborhood gives birth every...</td>\n",
       "      <td>2</td>\n",
       "      <td>[entailment, neutral, None]</td>\n",
       "      <td>There is a particular woman in this neighborho...</td>\n",
       "      <td>Every year, some woman in this neighborhood gi...</td>\n",
       "      <td>A woman gives birth to a child every year.</td>\n",
       "      <td>There is a particular woman with a birth rate ...</td>\n",
       "      <td>There is a particular woman with a birth rate ...</td>\n",
       "      <td>There is a particular woman with a birth rate ...</td>\n",
       "      <td>There is a particular woman in this neighborho...</td>\n",
       "      <td>Every year, some woman in this neighborhood gi...</td>\n",
       "      <td>A woman gives birth to a child every year.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            premise  \\\n",
       "0  132_c  A woman in this neighborhood gives birth every...   \n",
       "\n",
       "                                          hypothesis  \\\n",
       "0  There is a particular woman with a birth rate ...   \n",
       "\n",
       "                    ambiguous_sent_html  \\\n",
       "0  <span class=\"premise\">premise</span>   \n",
       "\n",
       "                                      ambiguous_sent  distractor_idx  \\\n",
       "0  A woman in this neighborhood gives birth every...               2   \n",
       "\n",
       "                        labels  \\\n",
       "0  [entailment, neutral, None]   \n",
       "\n",
       "                                            premise1  \\\n",
       "0  There is a particular woman in this neighborho...   \n",
       "\n",
       "                                            premise2  \\\n",
       "0  Every year, some woman in this neighborhood gi...   \n",
       "\n",
       "                                     premise3  \\\n",
       "0  A woman gives birth to a child every year.   \n",
       "\n",
       "                                         hypothesis1  \\\n",
       "0  There is a particular woman with a birth rate ...   \n",
       "\n",
       "                                         hypothesis2  \\\n",
       "0  There is a particular woman with a birth rate ...   \n",
       "\n",
       "                                         hypothesis3  \\\n",
       "0  There is a particular woman with a birth rate ...   \n",
       "\n",
       "                                     interpretation1  \\\n",
       "0  There is a particular woman in this neighborho...   \n",
       "\n",
       "                                     interpretation2  \\\n",
       "0  Every year, some woman in this neighborhood gi...   \n",
       "\n",
       "                              interpretation3  \n",
       "0  A woman gives birth to a child every year.  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df = create_validation_file(ambiguous_df, target_lang='yor_Latn')\n",
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59ffd2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df.to_csv('annotation/crowdworker_exp/examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e6062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
