{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3251a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/xlab/alisaliu/ambient/notebooks\n",
      "/mmfs1/gscratch/xlab/alisaliu/ambient\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'ambient':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc63933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mturk.back_translation import back_translate\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0857c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang='eng_Latn')\n",
    "t_tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang='yor_Latn')\n",
    "mt_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee720251",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50\n",
    "test_df = pd.read_json('annotation/AmbiEnt/test.jsonl', lines=True)\n",
    "test_df = test_df[test_df['premise_ambiguous'] ^ test_df['hypothesis_ambiguous']]\n",
    "sample_ids = test_df.sample(sample_size).id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0531c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example_csv(df):\n",
    "    examples = []\n",
    "    for i, row in tqdm(df.iterrows(), total=sample_size):\n",
    "        ambiguous_sentence_key = 'premise' if row['premise_ambiguous'] else 'hypothesis'\n",
    "        other_sentence_key = 'hypothesis' if row['premise_ambiguous'] else 'premise'\n",
    "        ambiguous_sentence = row[ambiguous_sentence_key]\n",
    "\n",
    "        disambiguations, labels = list(row['predicted_rewrites'].values()), list(row['predicted_rewrites'].keys())\n",
    "        \n",
    "        distractor_sentence = back_translate([ambiguous_sentence], mt_model, s_tokenizer, t_tokenizer)\n",
    "        distractor_idxs = random.sample(range(3), 3-len(disambiguations))\n",
    "        candidate_disambiguations, candidate_labels = [None]*3, [None]*3\n",
    "        \n",
    "        for j in range(len(candidate_disambiguations)):\n",
    "            if j in distractor_idxs:\n",
    "                candidate_disambiguations[j] = distractor_sentence\n",
    "            else:\n",
    "                candidate_disambiguations[j] = disambiguations[0]\n",
    "                disambiguations = disambiguations[1:]\n",
    "                candidate_labels[j] = labels[0]\n",
    "                labels = labels[1:]\n",
    "\n",
    "        ex = {\n",
    "            'id': row['id'],\n",
    "            'premise': row['premise'],\n",
    "            'hypothesis': row['hypothesis'],\n",
    "            'ambiguous_sent_html': f'<span class=\"{ambiguous_sentence_key}\">{ambiguous_sentence_key}</span>',\n",
    "            'ambiguous_sent': ambiguous_sentence,\n",
    "            'distractor_idxs': distractor_idxs,\n",
    "            'labels': candidate_labels,\n",
    "        }\n",
    "\n",
    "        for i in range(3):\n",
    "            ex[f'{ambiguous_sentence_key}{i+1}'] = candidate_disambiguations[i]\n",
    "            ex[f'{other_sentence_key}{i+1}'] = row[other_sentence_key]\n",
    "            ex[f'interpretation{i+1}'] = candidate_disambiguations[i]\n",
    "\n",
    "        examples.append(ex)\n",
    "    \n",
    "    pd.DataFrame(examples).to_csv(f'annotation/human_eval/examples_by_source/{model}_{sample_size}.csv', index=False)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f995fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/gscratch/cse/alisaliu/miniconda3/envs/nli/lib/python3.9/site-packages/transformers/generation/utils.py:1298: UserWarning: Using `max_length`'s default (200) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 50/50 [04:49<00:00,  5.78s/it]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/gscratch/cse/alisaliu/miniconda3/envs/nli/lib/python3.9/site-packages/transformers/generation/utils.py:1298: UserWarning: Using `max_length`'s default (200) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 50/50 [04:47<00:00,  5.76s/it]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/gscratch/cse/alisaliu/miniconda3/envs/nli/lib/python3.9/site-packages/transformers/generation/utils.py:1298: UserWarning: Using `max_length`'s default (200) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 50/50 [04:48<00:00,  5.77s/it]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/gscratch/cse/alisaliu/miniconda3/envs/nli/lib/python3.9/site-packages/transformers/generation/utils.py:1298: UserWarning: Using `max_length`'s default (200) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 50/50 [04:48<00:00,  5.78s/it]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/gscratch/cse/alisaliu/miniconda3/envs/nli/lib/python3.9/site-packages/transformers/generation/utils.py:1298: UserWarning: Using `max_length`'s default (200) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 50/50 [04:48<00:00,  5.78s/it]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/gscratch/cse/alisaliu/miniconda3/envs/nli/lib/python3.9/site-packages/transformers/generation/utils.py:1298: UserWarning: Using `max_length`'s default (200) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 50/50 [04:47<00:00,  5.76s/it]\n"
     ]
    }
   ],
   "source": [
    "for model in ['gpt-4', 'llama-65b', 'text-davinci-003', 'davinci', 'flan-t5-xxl', 'gpt-3.5-turbo']:\n",
    "    df = pd.read_json(f'results/generative_evaluation/{model}-n4.jsonl', lines=True)\n",
    "    df = df.loc[df['id'].isin(sample_ids)]\n",
    "    examples = create_example_csv(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bc38b4",
   "metadata": {},
   "source": [
    "## combine from different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c47c5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['gpt-3.5-turbo', 'gpt-4', 'llama-65b', 'text-davinci-003', 'davinci', 'flan-t5-xxl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0add3d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dfs = []\n",
    "for model in models:\n",
    "    model_df = pd.read_csv(f'annotation/human_eval/examples_by_source/{model}_50.csv')\n",
    "    model_df['source'] = model\n",
    "    model_dfs.append(model_df)\n",
    "\n",
    "example_df = pd.concat(model_dfs).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a355118",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df.to_csv('annotation/human_eval/examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9375eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_examples = len(example_df.index)\n",
    "for j, i in enumerate(np.arange(0, num_examples, batch_size)):\n",
    "    example_df.iloc[i:np.min([i+batch_size, num_examples])].to_csv(f'annotation/human_eval/next_batches/batch_{j}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71add864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
