{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a8907c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/xlab/alisaliu/ambient/notebooks\n",
      "/mmfs1/gscratch/xlab/alisaliu/ambient\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'ambient':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8850f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mturk.human_eval_utils import read_batch, clean_batch, statistics_for_worker\n",
    "from mturk.crowdworker_stats import get_disambiguation_idxs\n",
    "from utils.utils import get_mode\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0caa7caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dir = Path('annotation/human_eval/batches')\n",
    "batch_id = 5046064\n",
    "batch_df = read_batch(batch_id, batch_dir=batch_dir)\n",
    "results_df = clean_batch(batch_df)\n",
    "results_df.to_json(batch_dir / f'batch_{batch_id}/batch_results.jsonl', lines=True, orient='records')\n",
    "results_df['labels'] = [ast.literal_eval(l) for l in results_df.labels]\n",
    "results_df['distractor_idxs'] = [ast.literal_eval(d) for d in results_df.distractor_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa4c50d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '103_c',\n",
       "  'premise': 'Mykonos has had a head start as far as diving is concerned because it was never banned here (after all, there are no ancient sites to protect).',\n",
       "  'hypothesis': 'Diving was banned in places other than Mykonos.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'neutral'],\n",
       "  'interpretations': ['Mykonos had first made the journey up its trail because it had never been banned there (because there were no ancient areas to protect).',\n",
       "   'Diving was banned in places other than Mykonos.',\n",
       "   'Diving was never banned in places other than Mykonos.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '103_c',\n",
       "  'premise': 'Mykonos has had a head start as far as diving is concerned because it was never banned here (after all, there are no ancient sites to protect).',\n",
       "  'hypothesis': 'Diving was banned in places other than Mykonos.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'contradiction', None],\n",
       "  'interpretations': ['Diving was banned in places other than Mykonos.',\n",
       "   'Diving was banned in places other than Mykonos, and it was never banned in Mykonos.',\n",
       "   'Mykonos had first made the journey up its trail because it had never been banned there (because there were no ancient areas to protect).'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, True, False],\n",
       "  'd2_gold': [False, True, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '10452',\n",
       "  'premise': 'It is clear that our current education system is not preparing students for the real world.',\n",
       "  'hypothesis': 'Students should be prepared for the real world by our current education system.',\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'contradiction'],\n",
       "  'interpretations': ['Clearly, the current educational system does not prepare students for the world and for the world around us.',\n",
       "   'Our current education system is not preparing students for the real world, so it should.',\n",
       "   'Our current education system is not preparing students for the real world, so it should not.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'contradiction'],\n",
       "  'q3_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [True, True, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '10932',\n",
       "  'premise': \"The company's profits have been declining for the past three years.\",\n",
       "  'hypothesis': 'The company has been losing money for the past three years.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'neutral', None],\n",
       "  'interpretations': ['The company has been losing money for the past three years.',\n",
       "   \"The company has been losing money for the past three years, but it's about to turn around.\",\n",
       "   'The company had been losing money for the past three years.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '10932',\n",
       "  'premise': \"The company's profits have been declining for the past three years.\",\n",
       "  'hypothesis': 'The company has been losing money for the past three years.',\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['entailment', None, 'contradiction'],\n",
       "  'interpretations': ['The company has been making less money each year for the past three years.',\n",
       "   'The company had been losing money for the past three years.',\n",
       "   'The company has been losing money each year for the past three years.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'contradiction'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, False, True]},\n",
       " {'id': '109_c',\n",
       "  'premise': 'No one in the class is satisfied with their painting, except for Susan.',\n",
       "  'hypothesis': 'Only Susan likes her painting.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'neutral', None],\n",
       "  'interpretations': ['No one in the class is satisfied with their painting, except for Susan.',\n",
       "   'No one in the class is satisfied with their painting, except for Susan, and Susan is satisfied with her painting.',\n",
       "   'Susan was the only one who liked her art.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['entailment', 'neutral', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '109_c',\n",
       "  'premise': 'No one in the class is satisfied with their painting, except for Susan.',\n",
       "  'hypothesis': 'Only Susan likes her painting.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [2, 1, 0],\n",
       "  'labels': [None, None, None],\n",
       "  'interpretations': ['Susan was the only one who liked her art.',\n",
       "   'Susan was the only one who liked her art.',\n",
       "   'Susan was the only one who liked her art.'],\n",
       "  'q1_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '113_c',\n",
       "  'premise': 'Angie broke the news to her grandma that she has cancer.',\n",
       "  'hypothesis': 'Her grandma does not have cancer.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'contradiction', 'entailment'],\n",
       "  'interpretations': ['Angie told her grandmother that she had cancer.',\n",
       "   'Angie broke the news to her grandma that she has cancer, but her grandma does not have cancer.',\n",
       "   'Angie broke the news to her grandma that she has cancer, but her grandma does not have cancer yet.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, True, True],\n",
       "  'd2_gold': [False, True, True],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '113_c',\n",
       "  'premise': 'Angie broke the news to her grandma that she has cancer.',\n",
       "  'hypothesis': 'Her grandma does not have cancer.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'neutral', 'contradiction'],\n",
       "  'interpretations': ['Angie told her grandmother that she had cancer.',\n",
       "   'Angie broke the news to her grandma that Angie herself has cancer.',\n",
       "   'Angie broke the news to her grandma that her grandma has cancer.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'entailment'],\n",
       "  'q2_gold': ['entailment', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '113_c',\n",
       "  'premise': 'Angie broke the news to her grandma that she has cancer.',\n",
       "  'hypothesis': 'Her grandma does not have cancer.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'contradiction', 'entailment'],\n",
       "  'interpretations': ['Angie told her grandmother that she had cancer.',\n",
       "   'Angie broke the news to her grandma that she has cancer, and her grandma does not have cancer.',\n",
       "   'Angie broke the news to her grandma that she has cancer, and her grandma does have cancer.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'd1_gold': [False, True, True],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [True, True, False]},\n",
       " {'id': '120_c',\n",
       "  'premise': 'She needed to know only what he told her.',\n",
       "  'hypothesis': 'Other people may have told her the same thing.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['entailment', None, 'neutral'],\n",
       "  'interpretations': ['She only needed to know what he told her, and no one else told her the same thing.',\n",
       "   'He should know only what he said.',\n",
       "   'She only needed to know what he told her, but other people may have also told her the same thing.'],\n",
       "  'q1_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [True, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '120_c',\n",
       "  'premise': 'She needed to know only what he told her.',\n",
       "  'hypothesis': 'Other people may have told her the same thing.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'contradiction', 'neutral'],\n",
       "  'interpretations': ['He should know only what he said.',\n",
       "   'She needed to know only what he told her, and no one else provided her with the same information.',\n",
       "   \"She needed to know only what he told her, but it's possible that others also told her the same thing.\"],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, True, True],\n",
       "  'd3_gold': [False, True, True]},\n",
       " {'id': '120_c',\n",
       "  'premise': 'She needed to know only what he told her.',\n",
       "  'hypothesis': 'Other people may have told her the same thing.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'contradiction', 'neutral'],\n",
       "  'interpretations': ['He should know only what he said.',\n",
       "   'She needed to know only what he told her, and nothing else.',\n",
       "   'She needed to know only what he told her, and nothing else.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '12324',\n",
       "  'premise': 'He was elected to the position.',\n",
       "  'hypothesis': 'He was appointed to the position.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'contradiction', 'entailment'],\n",
       "  'interpretations': ['He was appointed to this position.',\n",
       "   'He was elected by a vote to the position.',\n",
       "   'He was appointed by someone to the position.'],\n",
       "  'q1_gold': ['neutral', 'contradiction', 'contradiction'],\n",
       "  'q2_gold': ['neutral', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'd1_gold': [False, True, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '130_c',\n",
       "  'premise': 'He told me the issue was resolved yesterday.',\n",
       "  'hypothesis': 'He told me yesterday.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'contradiction'],\n",
       "  'interpretations': ['He told me that the matter was resolved tonight.',\n",
       "   'He told me the issue was resolved yesterday.',\n",
       "   'He told me yesterday.'],\n",
       "  'q1_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q2_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '131_c',\n",
       "  'premise': 'She told me her mom was in town two weeks ago.',\n",
       "  'hypothesis': 'She told me two weeks ago.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['contradiction', None, 'neutral'],\n",
       "  'interpretations': [\"She told me her mom was in town two weeks ago, but she didn't tell me two weeks ago.\",\n",
       "   'He told me that his mother had been in town two weeks earlier.',\n",
       "   \"She told me her mom was in town two weeks ago, but she didn't tell me two weeks ago.\"],\n",
       "  'q1_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'd1_gold': [True, False, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, False, True]},\n",
       " {'id': '131_c',\n",
       "  'premise': 'She told me her mom was in town two weeks ago.',\n",
       "  'hypothesis': 'She told me two weeks ago.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'contradiction', None],\n",
       "  'interpretations': ['She told me her mom was in town two weeks ago.',\n",
       "   'She told me two weeks ago.',\n",
       "   'He told me that his mother had been in town two weeks earlier.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, True, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '131_c',\n",
       "  'premise': 'She told me her mom was in town two weeks ago.',\n",
       "  'hypothesis': 'She told me two weeks ago.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'neutral'],\n",
       "  'interpretations': ['He told me that his mother had been in town two weeks earlier.',\n",
       "   'She told me two weeks ago that her mom was in town.',\n",
       "   'She told me two weeks ago that her mom was in town, but she may have told me other things too.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'neutral', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '131_c',\n",
       "  'premise': 'She told me her mom was in town two weeks ago.',\n",
       "  'hypothesis': 'She told me two weeks ago.',\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'contradiction', None],\n",
       "  'interpretations': ['She told me two weeks ago that her mom was in town.',\n",
       "   'She told me recently that her mom was in town two weeks ago.',\n",
       "   'He told me that his mother had been in town two weeks earlier.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['contradiction', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'contradiction', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '138_c',\n",
       "  'premise': 'Alice said that Bob studied Spanish, and Charlie did too.',\n",
       "  'hypothesis': 'Charlie said that Bob studied Spanish.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'contradiction', None],\n",
       "  'interpretations': ['Alice said that Bob studied Spanish, and Charlie confirmed that he also studied Spanish.',\n",
       "   'Alice said that Bob studied Spanish, and Charlie said that he studied French.',\n",
       "   'Alice said that Bob learned Spanish and Charlie learned it.'],\n",
       "  'q1_gold': ['contradiction', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['contradiction', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['contradiction', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, True, False]},\n",
       " {'id': '138_c',\n",
       "  'premise': 'Alice said that Bob studied Spanish, and Charlie did too.',\n",
       "  'hypothesis': 'Charlie said that Bob studied Spanish.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'contradiction'],\n",
       "  'interpretations': ['Alice said that Bob learned Spanish and Charlie learned it.',\n",
       "   'Alice said that Bob studied Spanish, and Charlie did too.',\n",
       "   \"Alice said that Bob studied Spanish, and Charlie did too, but Charlie didn't say that Bob studied Spanish.\"],\n",
       "  'q1_gold': ['neutral', 'contradiction', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'contradiction', 'entailment'],\n",
       "  'q3_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, True]},\n",
       " {'id': '138_c',\n",
       "  'premise': 'Alice said that Bob studied Spanish, and Charlie did too.',\n",
       "  'hypothesis': 'Charlie said that Bob studied Spanish.',\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'contradiction', None],\n",
       "  'interpretations': ['Alice said that Bob studied Spanish, and Charlie confirmed it.',\n",
       "   'Alice said that Bob studied Spanish, and Charlie also studied Spanish.',\n",
       "   'Alice said that Bob learned Spanish and Charlie learned it.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['contradiction', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['contradiction', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '16733',\n",
       "  'premise': 'Even though he was failing, he refused to give up.',\n",
       "  'hypothesis': 'He refused to give up because he was failing.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'contradiction'],\n",
       "  'interpretations': ['He refused to give up because he could not.',\n",
       "   'He refused to give up because he was failing.',\n",
       "   'He refused to give up because he was failing.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '16733',\n",
       "  'premise': 'Even though he was failing, he refused to give up.',\n",
       "  'hypothesis': 'He refused to give up because he was failing.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'contradiction', None],\n",
       "  'interpretations': ['He refused to give up because he was failing, as in he felt he had no other choice.',\n",
       "   \"He refused to give up because he was failing, as in he thought he was doing well and didn't realize he was failing.\",\n",
       "   'He refused to give up because he could not.'],\n",
       "  'q1_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'q2_gold': ['contradiction', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '17497',\n",
       "  'premise': \"In some cases, the company's treasurer may be authorized to borrow funds on behalf of the company.\",\n",
       "  'hypothesis': 'The treasurer is not authorized to borrow funds.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['neutral', 'contradiction', None],\n",
       "  'interpretations': [\"In some cases, the company's treasurer may be authorized to borrow funds on behalf of the company.\",\n",
       "   \"In some cases, the company's treasurer may not be authorized to borrow funds on behalf of the company.\",\n",
       "   'Sometimes the finance director may be authorized to lend money to the company.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'contradiction'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '17497',\n",
       "  'premise': \"In some cases, the company's treasurer may be authorized to borrow funds on behalf of the company.\",\n",
       "  'hypothesis': 'The treasurer is not authorized to borrow funds.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['contradiction', 'entailment', None],\n",
       "  'interpretations': ['The treasurer is authorized to borrow funds in some cases, but not in others.',\n",
       "   'The treasurer is not authorized to borrow funds at all.',\n",
       "   'Sometimes the finance director may be authorized to lend money to the company.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'contradiction'],\n",
       "  'q2_gold': ['neutral', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '17497',\n",
       "  'premise': \"In some cases, the company's treasurer may be authorized to borrow funds on behalf of the company.\",\n",
       "  'hypothesis': 'The treasurer is not authorized to borrow funds.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['contradiction', None, 'entailment'],\n",
       "  'interpretations': [\"In some cases, the company's treasurer may be authorized to borrow funds on behalf of the company.\",\n",
       "   'Sometimes the finance director may be authorized to lend money to the company.',\n",
       "   \"In some cases, the company's treasurer may not be authorized to borrow funds on behalf of the company.\"],\n",
       "  'q1_gold': ['contradiction', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '1838',\n",
       "  'premise': \"The most likely explanation for the decline in support for the war is that the American public has lost faith in the government's ability to win the war.\",\n",
       "  'hypothesis': \"The American public has lost faith in the government's ability to win the war.\",\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['neutral', None, 'entailment'],\n",
       "  'interpretations': [\"The most likely explanation for the decline in support for the war is that the American public has lost faith in the government's ability to win the war, but there could be other explanations.\",\n",
       "   \"Perhaps his explanation for the decline was that the American people had lost faith in the government's ability to win the war.\",\n",
       "   \"The most likely explanation for the decline in support for the war is confirmed to be that the American public has lost faith in the government's ability to win the war.\"],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'neutral', 'entailment'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, False, False]},\n",
       " {'id': '1838',\n",
       "  'premise': \"The most likely explanation for the decline in support for the war is that the American public has lost faith in the government's ability to win the war.\",\n",
       "  'hypothesis': \"The American public has lost faith in the government's ability to win the war.\",\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'contradiction', None],\n",
       "  'interpretations': [\"The most likely explanation for the decline in support for the war is that the American public has lost faith in the government's ability to win the war.\",\n",
       "   \"The most likely explanation for the decline in support for the war is that the American public has lost faith in the government's ability to win the war.\",\n",
       "   \"Perhaps his explanation for the decline was that the American people had lost faith in the government's ability to win the war.\"],\n",
       "  'q1_gold': ['entailment', 'entailment', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '1_c',\n",
       "  'premise': \"My kids might go to the same school as Bill Gates' kids.\",\n",
       "  'hypothesis': 'My kids currently go to school.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'neutral', None],\n",
       "  'interpretations': ['My kids are currently enrolled in a school.',\n",
       "   \"My kids are not currently enrolled in a school, but there is a possibility they may attend the same school as Bill Gates' kids in the future.\",\n",
       "   \"My children may go to the same school as Bill Gates' children.\"],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '24870',\n",
       "  'premise': \"I was looking for my glasses and couldn't find them anywhere.\",\n",
       "  'hypothesis': 'I found my glasses on the kitchen table.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2, 1, 0],\n",
       "  'labels': [None, None, None],\n",
       "  'interpretations': ['I looked for my eyes, but I could not find them anywhere.',\n",
       "   'I looked for my eyes, but I could not find them anywhere.',\n",
       "   'I looked for my eyes, but I could not find them anywhere.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '24870',\n",
       "  'premise': \"I was looking for my glasses and couldn't find them anywhere.\",\n",
       "  'hypothesis': 'I found my glasses on the kitchen table.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [],\n",
       "  'labels': ['contradiction', 'entailment', 'neutral'],\n",
       "  'interpretations': [\"I was looking for my glasses and couldn't find them anywhere, implying that I never found them.\",\n",
       "   \"I was looking for my glasses and couldn't find them anywhere, but eventually found them on the kitchen table.\",\n",
       "   \"I was looking for my glasses and couldn't find them anywhere, but the context doesn't specify whether or not I eventually found them.\"],\n",
       "  'q1_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, True, True]},\n",
       " {'id': '2535',\n",
       "  'premise': 'In the past, people thought that the Earth was the center of the universe.',\n",
       "  'hypothesis': 'People now know that the Earth is not the center of the universe.',\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'neutral', None],\n",
       "  'interpretations': ['In the past, people believed that the Earth was the center of the universe.',\n",
       "   'In the past, people thought that the Earth might be the center of the universe.',\n",
       "   'In ancient times, people believed that the earth was the center of the universe.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [True, True, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '28157',\n",
       "  'premise': 'They will be moving to a new house next month.',\n",
       "  'hypothesis': 'They may be moving to a new house next month.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'neutral', None],\n",
       "  'interpretations': ['They may be moving to a new house next month.',\n",
       "   'They may be moving to a new house next month, but they may not.',\n",
       "   'They may move to a new home next month.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['contradiction', 'contradiction', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, False, True]},\n",
       " {'id': '30056',\n",
       "  'premise': 'I heard that the cat was stuck in the tree.',\n",
       "  'hypothesis': 'The cat was not stuck in the tree.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'neutral', None],\n",
       "  'interpretations': ['I heard that the cat was stuck in the tree, but it was not.',\n",
       "   'I heard that the cat was stuck in the tree, but it was not stuck in the tree.',\n",
       "   'I heard that your eggs are stuck in a tree.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, False],\n",
       "  'd2_gold': [True, True, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '30056',\n",
       "  'premise': 'I heard that the cat was stuck in the tree.',\n",
       "  'hypothesis': 'The cat was not stuck in the tree.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0, 1, 2],\n",
       "  'labels': [None, None, None],\n",
       "  'interpretations': ['I heard that your eggs are stuck in a tree.',\n",
       "   'I heard that your eggs are stuck in a tree.',\n",
       "   'I heard that your eggs are stuck in a tree.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '30056',\n",
       "  'premise': 'I heard that the cat was stuck in the tree.',\n",
       "  'hypothesis': 'The cat was not stuck in the tree.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [],\n",
       "  'labels': ['entailment', 'neutral', 'contradiction'],\n",
       "  'interpretations': ['I heard a rumor that the cat was stuck in the tree, but it turned out to be false.',\n",
       "   \"I heard that the cat was stuck in the tree, but I don't know if it's true or not.\",\n",
       "   'I heard and confirmed that the cat was stuck in the tree.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'd1_gold': [True, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, True, False]},\n",
       " {'id': '30056',\n",
       "  'premise': 'I heard that the cat was stuck in the tree.',\n",
       "  'hypothesis': 'The cat was not stuck in the tree.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['contradiction', 'neutral', None],\n",
       "  'interpretations': ['I heard that the cat was stuck in the tree.',\n",
       "   'I heard that the cat was not stuck in the tree.',\n",
       "   'I heard that your eggs are stuck in a tree.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '31944',\n",
       "  'premise': 'All of the students in the class are intelligent.',\n",
       "  'hypothesis': 'Some of the students in the class are intelligent.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['neutral', None, 'contradiction'],\n",
       "  'interpretations': ['Some of the students in the class are not intelligent.',\n",
       "   'Some of our classmates were very good.',\n",
       "   'Some of the students in the class are not intelligent, but they are in the class.'],\n",
       "  'q1_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'd1_gold': [False, True, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, True, False]},\n",
       " {'id': '31944',\n",
       "  'premise': 'All of the students in the class are intelligent.',\n",
       "  'hypothesis': 'Some of the students in the class are intelligent.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['contradiction', 'neutral', None],\n",
       "  'interpretations': ['Some of the students in the class are intelligent.',\n",
       "   'Some of the students in the class are intelligent.',\n",
       "   'Some of our classmates were very good.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '31944',\n",
       "  'premise': 'All of the students in the class are intelligent.',\n",
       "  'hypothesis': 'Some of the students in the class are intelligent.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['contradiction', None, 'entailment'],\n",
       "  'interpretations': ['Some of the students in the class are intelligent, but not all of them.',\n",
       "   'Some of our classmates were very good.',\n",
       "   'Some, perhaps all, of the students in the class are intelligent.'],\n",
       "  'q1_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, False, False]},\n",
       " {'id': '31944',\n",
       "  'premise': 'All of the students in the class are intelligent.',\n",
       "  'hypothesis': 'Some of the students in the class are intelligent.',\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'contradiction'],\n",
       "  'interpretations': ['Some of our classmates were very good.',\n",
       "   'Some of the students in the class are more intelligent than others.',\n",
       "   'Some of the students in the class are intelligent, but not all of them.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, True, True],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '34383',\n",
       "  'premise': 'We can be sure that the future will be better than the present.',\n",
       "  'hypothesis': 'The future will be better than the present.',\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'contradiction', None],\n",
       "  'interpretations': ['We can be sure that the future will be better than the present.',\n",
       "   'We can be sure that the future will be worse than the present.',\n",
       "   'We can be sure that the future is better than it is now.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, False, True]},\n",
       " {'id': '36_c',\n",
       "  'premise': 'She wants to work with Dr. Smith, the professor with the largest lab in the department.',\n",
       "  'hypothesis': 'She wants to work with the professor with the largest lab in the department.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'contradiction'],\n",
       "  'interpretations': ['He wanted to work with a professor who owned the largest laboratory in the department.',\n",
       "   \"She wants to work with the professor with the largest lab in the department, and she doesn't want to work with any other professors.\",\n",
       "   'She wants to work with the professor with the largest lab in the department, and she wants to work with other professors as well.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, True, False]},\n",
       " {'id': '36_c',\n",
       "  'premise': 'She wants to work with Dr. Smith, the professor with the largest lab in the department.',\n",
       "  'hypothesis': 'She wants to work with the professor with the largest lab in the department.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'neutral', None],\n",
       "  'interpretations': ['She wants to work with Dr. Smith.',\n",
       "   'She wants to work with the professor with the largest lab in the department.',\n",
       "   'He wanted to work with a professor who owned the largest laboratory in the department.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '36_c',\n",
       "  'premise': 'She wants to work with Dr. Smith, the professor with the largest lab in the department.',\n",
       "  'hypothesis': 'She wants to work with the professor with the largest lab in the department.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['contradiction', 'entailment', None],\n",
       "  'interpretations': ['She wants to work with Dr. Smith, who happens to have the largest lab in the department.',\n",
       "   'She wants to work with the professor who has the largest lab in the department, and that happens to be Dr. Smith.',\n",
       "   'He wanted to work with a professor who owned the largest laboratory in the department.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '36_c',\n",
       "  'premise': 'She wants to work with Dr. Smith, the professor with the largest lab in the department.',\n",
       "  'hypothesis': 'She wants to work with the professor with the largest lab in the department.',\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [0, 1],\n",
       "  'labels': [None, None, 'entailment'],\n",
       "  'interpretations': ['He wanted to work with a professor who owned the largest laboratory in the department.',\n",
       "   'He wanted to work with a professor who owned the largest laboratory in the department.',\n",
       "   'She wants to work with Dr. Smith, who has the largest lab in the department.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '37555',\n",
       "  'premise': \"He didn't see the big picture.\",\n",
       "  'hypothesis': 'He was missing the point.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'neutral', None],\n",
       "  'interpretations': [\"He didn't see the big picture, meaning he was missing the overall point or context.\",\n",
       "   \"He didn't see the big picture, but he may have understood the specific point or details.\",\n",
       "   'He did not see what was happening.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [True, True, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '37555',\n",
       "  'premise': \"He didn't see the big picture.\",\n",
       "  'hypothesis': 'He was missing the point.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'contradiction', None],\n",
       "  'interpretations': [\"He didn't see the big picture, and he was missing the point.\",\n",
       "   \"He didn't see the big picture, and he was missing the point.\",\n",
       "   'He did not see what was happening.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, True, False],\n",
       "  'd2_gold': [False, True, False],\n",
       "  'd3_gold': [False, False, True]},\n",
       " {'id': '37555',\n",
       "  'premise': \"He didn't see the big picture.\",\n",
       "  'hypothesis': 'He was missing the point.',\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'contradiction', None],\n",
       "  'interpretations': [\"He didn't see the big picture, so he was missing the point.\",\n",
       "   \"He didn't see the big picture, but he was not necessarily missing the point.\",\n",
       "   'He did not see what was happening.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [True, True, False],\n",
       "  'd3_gold': [False, False, True]},\n",
       " {'id': '40798',\n",
       "  'premise': 'They are planning to build a new highway that will connect the two cities.',\n",
       "  'hypothesis': 'The highway will connect the two cities.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [0, 1, 2],\n",
       "  'labels': [None, None, None],\n",
       "  'interpretations': ['This regional road would connect the two cities.',\n",
       "   'This regional road would connect the two cities.',\n",
       "   'This regional road would connect the two cities.'],\n",
       "  'q1_gold': ['entailment', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '40798',\n",
       "  'premise': 'They are planning to build a new highway that will connect the two cities.',\n",
       "  'hypothesis': 'The highway will connect the two cities.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'neutral', None],\n",
       "  'interpretations': ['The highway will definitely be built and connect the two cities.',\n",
       "   'The highway is intended to connect the two cities, but it may not be built or completed.',\n",
       "   'This regional road would connect the two cities.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [True, True, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '45244',\n",
       "  'premise': \"He's a charmer.\",\n",
       "  'hypothesis': 'He is a charming man.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0, 2, 1],\n",
       "  'labels': [None, None, None],\n",
       "  'interpretations': ['He was very fond of it.',\n",
       "   'He was very fond of it.',\n",
       "   'He was very fond of it.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '45528',\n",
       "  'premise': 'Social media has been shown to have a negative effect on self-esteem.',\n",
       "  'hypothesis': 'Self-esteem is related to social media use.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'neutral'],\n",
       "  'interpretations': ['Social media has shown that it has a negative impact on self-esteem.',\n",
       "   'Social media has been shown to have a negative effect on self-esteem, implying a relationship between the two.',\n",
       "   'Social media has been shown to have a negative effect on self-esteem, but the relationship may not be direct or causal.'],\n",
       "  'q1_gold': ['entailment', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'neutral', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'd1_gold': [True, False, True],\n",
       "  'd2_gold': [True, False, True],\n",
       "  'd3_gold': [False, False, True]},\n",
       " {'id': '45_c',\n",
       "  'premise': 'The turkey is ready to eat.',\n",
       "  'hypothesis': 'The turkey is alive.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2, 1, 0],\n",
       "  'labels': [None, None, None],\n",
       "  'interpretations': ['The portion is ready to eat.',\n",
       "   'The portion is ready to eat.',\n",
       "   'The portion is ready to eat.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '45_c',\n",
       "  'premise': 'The turkey is ready to eat.',\n",
       "  'hypothesis': 'The turkey is alive.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['contradiction', 'neutral', None],\n",
       "  'interpretations': ['The turkey has been cooked and is ready to be eaten.',\n",
       "   'The turkey is alive and ready to be eaten.',\n",
       "   'The portion is ready to eat.'],\n",
       "  'q1_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '55746',\n",
       "  'premise': 'It is my belief that the earth is round.',\n",
       "  'hypothesis': 'I am certain that the earth is round.',\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['contradiction', 'entailment', None],\n",
       "  'interpretations': ['I believe that the earth is round, but I am not certain.',\n",
       "   'I believe that the earth is round, and I am certain.',\n",
       "   'I believe that the universe is round.'],\n",
       "  'q1_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, False, True],\n",
       "  'd2_gold': [True, False, True],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '57249',\n",
       "  'premise': 'It is difficult to be a good role model for your children when you are not a good role model for yourself.',\n",
       "  'hypothesis': 'You have to be a good role model for yourself.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['entailment', None, 'neutral'],\n",
       "  'interpretations': ['It is difficult to be a good role model for your children when you are not a good role model for yourself, implying that being a good role model for yourself is necessary.',\n",
       "   'It is difficult to set a good example for your children when you yourself are not.',\n",
       "   'It is difficult to be a good role model for your children when you are not a good role model for yourself, but it may still be possible.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [False, True, False],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '57249',\n",
       "  'premise': 'It is difficult to be a good role model for your children when you are not a good role model for yourself.',\n",
       "  'hypothesis': 'You have to be a good role model for yourself.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'contradiction'],\n",
       "  'interpretations': ['It is difficult to set a good example for your children when you yourself are not.',\n",
       "   'It is difficult to be a good role model for your children when you are not a good role model for yourself.',\n",
       "   'It is difficult to be a good role model for your children when you are not a good role model for yourself.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'entailment'],\n",
       "  'd1_gold': [False, False, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '57_c',\n",
       "  'premise': 'John and Jim are married.',\n",
       "  'hypothesis': 'John and Jim are a couple.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'contradiction'],\n",
       "  'interpretations': ['John and Jim are married.',\n",
       "   'John and Jim are married to each other.',\n",
       "   'John and Jim are both married, but not to each other.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'contradiction', 'contradiction'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '58103',\n",
       "  'premise': \"The Board rejected the union's argument that the employees were entitled to overtime compensation because they were required to attend mandatory training sessions outside of their regular work hours.\",\n",
       "  'hypothesis': 'The employees were not entitled to overtime compensation because they were required to attend mandatory training sessions outside of their regular work hours.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['contradiction', 'entailment', None],\n",
       "  'interpretations': ['The employees were not entitled to overtime compensation, and the reason for this is that they were required to attend mandatory training sessions outside of their regular work hours.',\n",
       "   'The employees were not entitled to overtime compensation, as concluded by the Board, because they were required to attend mandatory training sessions outside of their regular work hours.',\n",
       "   'The workers were not entitled to compensation for their work because they had to attend unnecessary training meetings in their working hours.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [False, True, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '58103',\n",
       "  'premise': \"The Board rejected the union's argument that the employees were entitled to overtime compensation because they were required to attend mandatory training sessions outside of their regular work hours.\",\n",
       "  'hypothesis': 'The employees were not entitled to overtime compensation because they were required to attend mandatory training sessions outside of their regular work hours.',\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'contradiction', None],\n",
       "  'interpretations': [\"The Board rejected the union's argument that the employees were entitled to overtime compensation because they were required to attend mandatory training sessions outside of their regular work hours.\",\n",
       "   'The employees were not entitled to overtime compensation regardless of whether they were required to attend mandatory training sessions outside of their regular work hours.',\n",
       "   'The workers were not entitled to compensation for their work because they had to attend unnecessary training meetings in their working hours.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['entailment', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, False, False],\n",
       "  'd3_gold': [True, False, False]},\n",
       " {'id': '59057',\n",
       "  'premise': 'As the use of fossil fuels decreases, the need for renewable energy sources will increase.',\n",
       "  'hypothesis': 'The need for renewable energy sources will increase.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [],\n",
       "  'labels': ['neutral', 'contradiction', 'entailment'],\n",
       "  'interpretations': ['The need for renewable energy sources will increase, but the need for fossil fuels will decrease.',\n",
       "   'The need for renewable energy sources will increase, but the need for fossil fuels will not decrease.',\n",
       "   'The need for renewable energy sources will increase, and the need for fossil fuels will decrease.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [True, True, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, True, False]},\n",
       " {'id': '59057',\n",
       "  'premise': 'As the use of fossil fuels decreases, the need for renewable energy sources will increase.',\n",
       "  'hypothesis': 'The need for renewable energy sources will increase.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'contradiction'],\n",
       "  'interpretations': ['As the use of wind energy decreases, the demand for renewable energy will increase.',\n",
       "   'The use of fossil fuels will decrease.',\n",
       "   'The use of fossil fuels will decrease.'],\n",
       "  'q1_gold': ['entailment', 'neutral', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, True, False],\n",
       "  'd3_gold': [False, True, False]},\n",
       " {'id': '59057',\n",
       "  'premise': 'As the use of fossil fuels decreases, the need for renewable energy sources will increase.',\n",
       "  'hypothesis': 'The need for renewable energy sources will increase.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'neutral'],\n",
       "  'interpretations': ['As the use of wind energy decreases, the demand for renewable energy will increase.',\n",
       "   'The decrease in the use of fossil fuels will directly lead to an increase in the need for renewable energy sources.',\n",
       "   'The decrease in the use of fossil fuels may not necessarily lead to an increase in the need for renewable energy sources, as other factors may come into play.'],\n",
       "  'q1_gold': ['neutral', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [True, False, False]},\n",
       " {'id': '59057',\n",
       "  'premise': 'As the use of fossil fuels decreases, the need for renewable energy sources will increase.',\n",
       "  'hypothesis': 'The need for renewable energy sources will increase.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'contradiction'],\n",
       "  'interpretations': ['As the use of wind energy decreases, the demand for renewable energy will increase.',\n",
       "   'The need for renewable energy sources will increase because the use of fossil fuels decreases.',\n",
       "   'The need for renewable energy sources will increase because the use of fossil fuels increases.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'entailment'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '59560',\n",
       "  'premise': 'The poet laureate is an honorary position given to a poet by a government or institution.',\n",
       "  'hypothesis': 'The poet laureate is a position given to a poet by a government or institution.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'contradiction', 'entailment'],\n",
       "  'interpretations': ['A secretary is a position given to a writer by a government or agency.',\n",
       "   'The poet laureate is always given by a government or institution.',\n",
       "   'The poet laureate is sometimes given by a government or institution.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['contradiction', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, True, True]},\n",
       " {'id': '59560',\n",
       "  'premise': 'The poet laureate is an honorary position given to a poet by a government or institution.',\n",
       "  'hypothesis': 'The poet laureate is a position given to a poet by a government or institution.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['entailment', None, 'contradiction'],\n",
       "  'interpretations': ['The poet laureate is a position given to a poet by a government or institution, without specifying whether it is honorary or not.',\n",
       "   'A secretary is a position given to a writer by a government or agency.',\n",
       "   'The poet laureate is a position given to a poet by a government or institution, implying that it is not honorary.'],\n",
       "  'q1_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['contradiction', 'entailment', 'contradiction'],\n",
       "  'd1_gold': [False, False, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '60459',\n",
       "  'premise': \"The more you practice, the better you'll get.\",\n",
       "  'hypothesis': \"If you don't practice, you'll never get better.\",\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['entailment', None, 'neutral'],\n",
       "  'interpretations': [\"If you don't practice, you'll never get better.\",\n",
       "   'As you study, you will improve.',\n",
       "   \"If you don't practice, you'll never get better, but you might get better anyway.\"],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['contradiction', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '60459',\n",
       "  'premise': \"The more you practice, the better you'll get.\",\n",
       "  'hypothesis': \"If you don't practice, you'll never get better.\",\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['contradiction', None, 'neutral'],\n",
       "  'interpretations': [\"If you don't practice, you'll never get better.\",\n",
       "   'As you study, you will improve.',\n",
       "   \"The more you practice, the better you'll get.\"],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, True, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '60459',\n",
       "  'premise': \"The more you practice, the better you'll get.\",\n",
       "  'hypothesis': \"If you don't practice, you'll never get better.\",\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'contradiction', 'entailment'],\n",
       "  'interpretations': ['As you study, you will improve.',\n",
       "   \"The more you practice, the better you'll get.\",\n",
       "   \"If you don't practice, you won't get better.\"],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, True]},\n",
       " {'id': '63_c',\n",
       "  'premise': \"He always flouts his mother's advice to follow his own dreams.\",\n",
       "  'hypothesis': 'He follows his dreams.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['contradiction', None, 'neutral'],\n",
       "  'interpretations': [\"He follows his mother's advice to follow his own dreams.\",\n",
       "   \"He disobeyed his mother's advice to pursue his dreams.\",\n",
       "   \"He follows his mother's advice to follow his own dreams.\"],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['entailment', 'contradiction', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '63_c',\n",
       "  'premise': \"He always flouts his mother's advice to follow his own dreams.\",\n",
       "  'hypothesis': 'He follows his dreams.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'contradiction'],\n",
       "  'interpretations': [\"He disobeyed his mother's advice to pursue his dreams.\",\n",
       "   \"He always flouts his mother's advice to follow his own dreams, meaning he disregards her advice and follows his dreams anyway.\",\n",
       "   \"He always flouts his mother's advice to follow his own dreams, meaning he disregards her advice and does not follow his dreams.\"],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'd1_gold': [True, True, False],\n",
       "  'd2_gold': [True, False, True],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '75121',\n",
       "  'premise': 'The painting is a copy of the original.',\n",
       "  'hypothesis': 'The painting is an imitation of the original.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'neutral'],\n",
       "  'interpretations': ['The picture is a copy of the original.',\n",
       "   'The painting is a copy of the original, and only that.',\n",
       "   'The painting is a copy of the original, and possibly other things too.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'entailment'],\n",
       "  'q2_gold': ['entailment', 'neutral', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'entailment'],\n",
       "  'd1_gold': [True, False, True],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '75121',\n",
       "  'premise': 'The painting is a copy of the original.',\n",
       "  'hypothesis': 'The painting is an imitation of the original.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['entailment', None, 'contradiction'],\n",
       "  'interpretations': ['The painting is a faithful reproduction of the original.',\n",
       "   'The picture is a copy of the original.',\n",
       "   'The painting is a cheap knockoff of the original.'],\n",
       "  'q1_gold': ['contradiction', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [True, False, False],\n",
       "  'd2_gold': [False, True, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '75121',\n",
       "  'premise': 'The painting is a copy of the original.',\n",
       "  'hypothesis': 'The painting is an imitation of the original.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'contradiction', None],\n",
       "  'interpretations': ['The painting is a copy of the original.',\n",
       "   'The painting is a copy of the original, but it is not an imitation.',\n",
       "   'The picture is a copy of the original.'],\n",
       "  'q1_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'q2_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q3_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, False, True],\n",
       "  'd3_gold': [False, True, True]},\n",
       " {'id': '79_c',\n",
       "  'premise': 'Calvin will honor his father and Otto will too.',\n",
       "  'hypothesis': \"Otto will not honor Calvin's father.\",\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'neutral', 'contradiction'],\n",
       "  'interpretations': ['Calvin would honor his father, and Otto would.',\n",
       "   'Calvin will honor his father, and Otto will too.',\n",
       "   'Calvin will honor his father, and Otto will not.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'contradiction', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '79_c',\n",
       "  'premise': 'Calvin will honor his father and Otto will too.',\n",
       "  'hypothesis': \"Otto will not honor Calvin's father.\",\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['contradiction', None, 'neutral'],\n",
       "  'interpretations': [\"Calvin will honor his father, and Otto will also honor Calvin's father.\",\n",
       "   'Calvin would honor his father, and Otto would.',\n",
       "   'Calvin will honor his father, and Otto will honor his own father.'],\n",
       "  'q1_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '82457',\n",
       "  'premise': 'All things being equal, she would have chosen the job in New York.',\n",
       "  'hypothesis': 'She chose the job in New York.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['contradiction', 'entailment', None],\n",
       "  'interpretations': ['All things being equal, she would have chosen the job in New York, but she was offered a better job in Chicago.',\n",
       "   'All things being equal, she would have chosen the job in New York, but she was offered a better job in Chicago, and she chose the job in New York.',\n",
       "   'If all went well, she would move to New York.'],\n",
       "  'q1_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '82457',\n",
       "  'premise': 'All things being equal, she would have chosen the job in New York.',\n",
       "  'hypothesis': 'She chose the job in New York.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'neutral', 'entailment'],\n",
       "  'interpretations': ['If all went well, she would move to New York.',\n",
       "   'If all things were equal, she would have chosen the job in New York, but they were not equal.',\n",
       "   'All things were equal, and she chose the job in New York.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['contradiction', 'contradiction', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '82457',\n",
       "  'premise': 'All things being equal, she would have chosen the job in New York.',\n",
       "  'hypothesis': 'She chose the job in New York.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['contradiction', None, 'entailment'],\n",
       "  'interpretations': ['All things were not equal, so she did not choose the job in New York.',\n",
       "   'If all went well, she would move to New York.',\n",
       "   'All things were equal, so she chose the job in New York.'],\n",
       "  'q1_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [True, True, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '82833',\n",
       "  'premise': 'Even the best-laid plans can go awry.',\n",
       "  'hypothesis': 'The best-laid plans are never successful.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'neutral', 'contradiction'],\n",
       "  'interpretations': ['Even the best of efforts can fail.',\n",
       "   'Even the best-laid plans can go wrong.',\n",
       "   'Even the best-laid plans are never successful.'],\n",
       "  'q1_gold': ['neutral', 'contradiction', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'contradiction', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [True, True, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '82833',\n",
       "  'premise': 'Even the best-laid plans can go awry.',\n",
       "  'hypothesis': 'The best-laid plans are never successful.',\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['contradiction', 'neutral', None],\n",
       "  'interpretations': ['Even the best-laid plans can fail.',\n",
       "   'Even the best-laid plans can be disrupted.',\n",
       "   'Even the best of efforts can fail.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [False, True, False]},\n",
       " {'id': '83044',\n",
       "  'premise': \"She's about to leave for her vacation.\",\n",
       "  'hypothesis': \"She's leaving for her vacation.\",\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['entailment', None, 'contradiction'],\n",
       "  'interpretations': [\"She's leaving for her vacation.\",\n",
       "   'He was on his way to a place of rest.',\n",
       "   \"She's about to leave for her vacation.\"],\n",
       "  'q1_gold': ['entailment', 'contradiction', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '83044',\n",
       "  'premise': \"She's about to leave for her vacation.\",\n",
       "  'hypothesis': \"She's leaving for her vacation.\",\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'neutral'],\n",
       "  'interpretations': ['He was on his way to a place of rest.',\n",
       "   'She is leaving right now for her vacation.',\n",
       "   'She will be leaving soon for her vacation.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'contradiction', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '83044',\n",
       "  'premise': \"She's about to leave for her vacation.\",\n",
       "  'hypothesis': \"She's leaving for her vacation.\",\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['entailment', None, 'neutral'],\n",
       "  'interpretations': [\"She's leaving for her vacation right now.\",\n",
       "   'He was on his way to a place of rest.',\n",
       "   \"She's leaving for her vacation at some point in the future.\"],\n",
       "  'q1_gold': ['entailment', 'contradiction', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '84765',\n",
       "  'premise': 'He was a great man and will be missed.',\n",
       "  'hypothesis': 'His death is a great loss.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [],\n",
       "  'labels': ['entailment', 'neutral', 'contradiction'],\n",
       "  'interpretations': ['He was a great man and will be missed.',\n",
       "   'He was a great man and will be missed.',\n",
       "   'He was a great man and will be missed.'],\n",
       "  'q1_gold': ['neutral', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '84765',\n",
       "  'premise': 'He was a great man and will be missed.',\n",
       "  'hypothesis': 'His death is a great loss.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['entailment', None, 'neutral'],\n",
       "  'interpretations': ['He was a great man and his death is a great loss.',\n",
       "   'He was a man of great importance.',\n",
       "   'He was a great man, but his death may not necessarily be a great loss.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, False, True],\n",
       "  'd2_gold': [True, False, False],\n",
       "  'd3_gold': [True, True, False]},\n",
       " {'id': '84765',\n",
       "  'premise': 'He was a great man and will be missed.',\n",
       "  'hypothesis': 'His death is a great loss.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [],\n",
       "  'labels': ['entailment', 'contradiction', 'neutral'],\n",
       "  'interpretations': ['He was a great man and will be missed, so his death is a great loss.',\n",
       "   'He was a great man and will be missed, but his death is not a great loss.',\n",
       "   'He was a great man and will be missed, but his death is inconclusive.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, False, False],\n",
       "  'd2_gold': [True, False, False],\n",
       "  'd3_gold': [False, False, True]},\n",
       " {'id': '85445',\n",
       "  'premise': 'A significant number of people who live in poverty are children.',\n",
       "  'hypothesis': 'A significant number of people who live in poverty are not children.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'contradiction', None],\n",
       "  'interpretations': ['A significant number of people who live in poverty are children, but there are also many adults who live in poverty.',\n",
       "   'A significant number of people who live in poverty are children, and there are very few adults who live in poverty.',\n",
       "   'Children are the largest proportion of people living in poverty.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q3_gold': ['contradiction', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, True, True],\n",
       "  'd2_gold': [False, True, True],\n",
       "  'd3_gold': [False, False, True]},\n",
       " {'id': '85445',\n",
       "  'premise': 'A significant number of people who live in poverty are children.',\n",
       "  'hypothesis': 'A significant number of people who live in poverty are not children.',\n",
       "  'source': 'text-davinci-003',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'contradiction', 'entailment'],\n",
       "  'interpretations': ['Children are the largest proportion of people living in poverty.',\n",
       "   'A significant number of people who live in poverty are children, and there are no other people who live in poverty.',\n",
       "   'A significant number of people who live in poverty are children, but there are also other people who live in poverty.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['contradiction', 'contradiction', 'contradiction'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, True, False],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '86796',\n",
       "  'premise': 'We should try a different strategy.',\n",
       "  'hypothesis': 'Trying a different strategy would be good.',\n",
       "  'source': 'gpt-3.5-turbo',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['entailment', None, 'contradiction'],\n",
       "  'interpretations': ['Trying a different strategy would be beneficial.',\n",
       "   'Another way is better.',\n",
       "   'Trying a different strategy would not be beneficial.'],\n",
       "  'q1_gold': ['entailment', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['contradiction', 'contradiction', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '86796',\n",
       "  'premise': 'We should try a different strategy.',\n",
       "  'hypothesis': 'Trying a different strategy would be good.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'neutral'],\n",
       "  'interpretations': ['Another way is better.',\n",
       "   'Trying a different strategy would be good in comparison to the current strategy.',\n",
       "   'Trying a different strategy would be enjoyable.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [False, False, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [True, True, True]},\n",
       " {'id': '93_c',\n",
       "  'premise': 'Noah took several pictures of Carlos, and he wonders which one Carlos likes best.',\n",
       "  'hypothesis': 'Noah wonders which picture of himself Carlos likes best.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [0, 1, 2],\n",
       "  'labels': [None, None, None],\n",
       "  'interpretations': [\"Noah was thinking about Carlos' favorite picture.\",\n",
       "   \"Noah was thinking about Carlos' favorite picture.\",\n",
       "   \"Noah was thinking about Carlos' favorite picture.\"],\n",
       "  'q1_gold': ['entailment', 'entailment', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'neutral'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'neutral'],\n",
       "  'd1_gold': [False, True, False],\n",
       "  'd2_gold': [False, True, False],\n",
       "  'd3_gold': [False, True, False]},\n",
       " {'id': '93_c',\n",
       "  'premise': 'Noah took several pictures of Carlos, and he wonders which one Carlos likes best.',\n",
       "  'hypothesis': 'Noah wonders which picture of himself Carlos likes best.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'contradiction'],\n",
       "  'interpretations': [\"Noah was thinking about Carlos' favorite picture.\",\n",
       "   'Noah wonders which picture of Carlos (himself referring to Carlos) Carlos likes best.',\n",
       "   'Noah wonders which picture of Noah (himself referring to Noah) Carlos likes best.'],\n",
       "  'q1_gold': ['neutral', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'contradiction'],\n",
       "  'd1_gold': [False, True, False],\n",
       "  'd2_gold': [True, False, True],\n",
       "  'd3_gold': [True, False, True]},\n",
       " {'id': '93_c',\n",
       "  'premise': 'Noah took several pictures of Carlos, and he wonders which one Carlos likes best.',\n",
       "  'hypothesis': 'Noah wonders which picture of himself Carlos likes best.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'hypothesis',\n",
       "  'distractor_idxs': [1],\n",
       "  'labels': ['neutral', None, 'contradiction'],\n",
       "  'interpretations': ['Noah wonders which picture of Carlos he likes best.',\n",
       "   \"Noah was thinking about Carlos' favorite picture.\",\n",
       "   'Noah wonders which picture of himself Carlos likes best.'],\n",
       "  'q1_gold': ['entailment', 'neutral', 'entailment'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, False, True],\n",
       "  'd2_gold': [False, False, False],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '94969',\n",
       "  'premise': 'I always feel more comfortable when I am at home.',\n",
       "  'hypothesis': 'I never feel more comfortable than when I am at home.',\n",
       "  'source': 'davinci',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'entailment', 'neutral'],\n",
       "  'interpretations': ['I find it easier to be at home.',\n",
       "   'I always feel more comfortable when I am at home, and I never feel more comfortable than when I am at home.',\n",
       "   'I always feel more comfortable when I am at home, but I never feel more comfortable than when I am at home.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, True, False],\n",
       "  'd2_gold': [True, True, True],\n",
       "  'd3_gold': [True, False, True]},\n",
       " {'id': '94969',\n",
       "  'premise': 'I always feel more comfortable when I am at home.',\n",
       "  'hypothesis': 'I never feel more comfortable than when I am at home.',\n",
       "  'source': 'flan-t5-xxl',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [1, 0, 2],\n",
       "  'labels': [None, None, None],\n",
       "  'interpretations': ['I find it easier to be at home.',\n",
       "   'I find it easier to be at home.',\n",
       "   'I find it easier to be at home.'],\n",
       "  'q1_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, False, False],\n",
       "  'd2_gold': [True, False, False],\n",
       "  'd3_gold': [True, False, False]},\n",
       " {'id': '94969',\n",
       "  'premise': 'I always feel more comfortable when I am at home.',\n",
       "  'hypothesis': 'I never feel more comfortable than when I am at home.',\n",
       "  'source': 'gpt-4',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [2],\n",
       "  'labels': ['entailment', 'neutral', None],\n",
       "  'interpretations': ['Whenever I am at home, I feel more comfortable than in any other situation.',\n",
       "   'I generally feel more comfortable at home, but there may be other situations where I feel equally or more comfortable.',\n",
       "   'I find it easier to be at home.'],\n",
       "  'q1_gold': ['entailment', 'entailment', 'entailment'],\n",
       "  'q2_gold': ['contradiction', 'neutral', 'neutral'],\n",
       "  'q3_gold': ['neutral', 'neutral', 'neutral'],\n",
       "  'd1_gold': [True, True, True],\n",
       "  'd2_gold': [False, False, True],\n",
       "  'd3_gold': [False, False, False]},\n",
       " {'id': '94969',\n",
       "  'premise': 'I always feel more comfortable when I am at home.',\n",
       "  'hypothesis': 'I never feel more comfortable than when I am at home.',\n",
       "  'source': 'llama-65b',\n",
       "  'ambiguous_sent': 'premise',\n",
       "  'distractor_idxs': [0],\n",
       "  'labels': [None, 'neutral', 'contradiction'],\n",
       "  'interpretations': ['I find it easier to be at home.',\n",
       "   'I always feel more comfortable when I am at home (not to address the question of whether I feel more comfortable elsewhere).',\n",
       "   'I always feel more comfortable when I am at home (not to address the question of whether I feel more comfortable elsewhere).'],\n",
       "  'q1_gold': ['neutral', 'entailment', 'neutral'],\n",
       "  'q2_gold': ['neutral', 'entailment', 'entailment'],\n",
       "  'q3_gold': ['neutral', 'entailment', 'entailment'],\n",
       "  'd1_gold': [False, True, True],\n",
       "  'd2_gold': [True, True, False],\n",
       "  'd3_gold': [True, True, False]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441762a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['correct'] = False\n",
    "for i, row in results_df.iterrows():\n",
    "    disambiguation_idxs = [j for j, label in enumerate(row['labels']) if label]\n",
    "    if len(disambiguation_idxs) >= 2:\n",
    "        if np.all([(get_mode(row[f'd{j+1}_gold']) == True) and (get_mode(row[f'q{j+1}_gold']) == row['labels'][j]) for j in disambiguation_idxs]):\n",
    "            results_df.at[i, 'correct'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c925725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[j for j, label in enumerate(row['labels']) if label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22e6b3a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davinci 20 0.0\n",
      "flan-t5-xxl 15 0.5333333333333333\n",
      "gpt-3.5-turbo 16 0.1875\n",
      "gpt-4 18 0.2777777777777778\n",
      "llama-65b 17 0.0\n",
      "text-davinci-003 14 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "for model, model_df in results_df.groupby('source'):\n",
    "    print(model, len(model_df.index), np.sum(model_df.correct)/len(model_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b66ec493",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row = results_df.loc[results_df['source'] == 'flan-t5-xxl'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bca47a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1HKYY6XI2OHO1    30\n",
       "A2EDER9628S0A     29\n",
       "AQXRHIMQ7UK7O     27\n",
       "ATR6RB1RULOC0     26\n",
       "A2NAKIXS3DVGAA    23\n",
       "A2BK45LZGGWPLX    23\n",
       "A3P9TM5PRYBH90    23\n",
       "AKQAI78JTXXC9     21\n",
       "A6KOTWP7N7RLU     20\n",
       "A1P3HHEXWNLJMP    19\n",
       "A1DMXEJGJY02E1    18\n",
       "A38DXFI1TZA295    18\n",
       "A2OFN0A5CPLH57     8\n",
       "A5TWD5QD99GZY      8\n",
       "A2TCX20FIMNWSS     7\n",
       "Name: worker_id, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_df.worker_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c071278f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_df.loc[batch_df['feedback'] != '{}'].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df.loc[batch_df['hypothesis'].str.startswith('Jon')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb4fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_df.loc[batch_df['worker_id'] == 'A9HQ3E0F2AGVO'].to_dict(orient='recods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c01b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374652fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
