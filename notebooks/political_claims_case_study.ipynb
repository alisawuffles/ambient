{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aeacc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/xlab/alisaliu/ambient\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'ambient':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5baf7695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from generation.gpt3_generation import request\n",
    "from utils.utils import sigmoid, predict_nli\n",
    "from utils.constants import NLI_LABELS\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94bbf341",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_model = RobertaForSequenceClassification.from_pretrained('models/roberta-large-wanli-multilabel').to('cuda')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('models/roberta-large-wanli-multilabel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989c2727",
   "metadata": {},
   "source": [
    "## detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3099dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_gpt3(sentence, n, top_p=0.9, engine='text-davinci-003'):\n",
    "    generations = set()\n",
    "    for i in range(n):\n",
    "        instruction = 'Paraphrase the text.'\n",
    "        context = f'{instruction}\\n\\n{sentence}\\nParaphrase: '\n",
    "        generation = request(\n",
    "            prompt=context,\n",
    "            model=engine,\n",
    "            top_p=top_p,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            return_only_text=True\n",
    "        )\n",
    "        \n",
    "        generation = generation.replace('Paraphrase:', '').strip()\n",
    "        generations.add(generation)\n",
    "\n",
    "    generations.discard('')\n",
    "    generations.discard(sentence)\n",
    "    return generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8872ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_df = pd.read_json('data/claim-decomp/dev.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f2229e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [14:31<00:00,  4.36s/it]\n"
     ]
    }
   ],
   "source": [
    "strings_to_remove = ['Says that', 'Says', '“', '\"', '”', '(', ')']\n",
    "\n",
    "claims_df['cleaned_claim'] = None\n",
    "claims_df['ambiguity_score'] = None\n",
    "claims_df['paraphrases'] = None\n",
    "claims_df['paraphrases'] = claims_df['paraphrases'].astype('object')\n",
    "for i, row in tqdm(claims_df.iterrows(), total=len(claims_df.index)):\n",
    "    claim = row['claim']\n",
    "    for s in strings_to_remove:\n",
    "        claim = claim.replace(s, '')\n",
    "    claim = claim.strip()\n",
    "    claim = claim[0].upper() + claim[1:]\n",
    "    paraphrases = paraphrase_gpt3(claim, n=5, engine='text-davinci-003', top_p=0.4)\n",
    "    scores = []\n",
    "    for paraphrase in paraphrases:\n",
    "        probs = predict_nli(claim, paraphrase, multilabel_model, tokenizer)\n",
    "        s = sorted([p for p in probs.values()], reverse=True)[1]\n",
    "        scores.append(s)\n",
    "    claims_df.at[i, 'cleaned_claim'] = claim\n",
    "    claims_df.at[i, 'paraphrases'] = [(p,s) for p,s in zip(paraphrases, scores)]\n",
    "    claims_df.at[i, 'ambiguity_score'] = np.nanmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98171dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_df.to_json('political-claims/results.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e6e4d2",
   "metadata": {},
   "source": [
    "## analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d33c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv('political-claims/dev-annotations.csv').drop('notes', axis=1)\n",
    "claims_df = pd.read_json('political-claims/results.jsonl', lines=True)[['example_id', 'label', 'claim', 'cleaned_claim', 'ambiguity_score', 'paraphrases']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a28d19c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>label</th>\n",
       "      <th>claim</th>\n",
       "      <th>ambiguity_score</th>\n",
       "      <th>paraphrases</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8057719209342304749</td>\n",
       "      <td>false</td>\n",
       "      <td>With voting by mail, you get thousands and tho...</td>\n",
       "      <td>0.847081</td>\n",
       "      <td>[[With voting by mail, people can fill out bal...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3333998957238197422</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>I’ve already traveled to Washington, D.C., and...</td>\n",
       "      <td>0.094361</td>\n",
       "      <td>[[I have already gone to Washington, D.C. and ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5816336384767541299</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>When San Francisco banned plastic grocery bags...</td>\n",
       "      <td>0.018198</td>\n",
       "      <td>[[The number of people going to the ER with fo...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            example_id        label  \\\n",
       "0  8057719209342304749        false   \n",
       "1 -3333998957238197422  barely-true   \n",
       "2 -5816336384767541299  barely-true   \n",
       "\n",
       "                                               claim  ambiguity_score  \\\n",
       "0  With voting by mail, you get thousands and tho...         0.847081   \n",
       "1  I’ve already traveled to Washington, D.C., and...         0.094361   \n",
       "2  When San Francisco banned plastic grocery bags...         0.018198   \n",
       "\n",
       "                                         paraphrases annotation  \n",
       "0  [[With voting by mail, people can fill out bal...          f  \n",
       "1  [[I have already gone to Washington, D.C. and ...          f  \n",
       "2  [[The number of people going to the ER with fo...          a  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = claims_df.merge(annotations[['claim', 'annotation']], how='inner', on='claim')\n",
    "results_df = results_df.drop('claim', axis=1).rename({'cleaned_claim': 'claim'}, axis=1)\n",
    "results_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b318865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12403100775193798\n",
      "0.8888888888888888\n",
      "0.21768707482993196\n"
     ]
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "t = sigmoid(-1.97) # mean threshold tuned on AmbiEnt dev set from §5 (see Table 11)\n",
    "y_pred = [1 if a > t else 0 for a in results_df.ambiguity_score]\n",
    "y_true = [1 if a == 'a' else 0 for a in results_df.annotation]\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(recall_score(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab93e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contradiction': 0.007283803541213274, 'entailment': 0.9960212111473083, 'neutral': 0.1750793308019638}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gscratch/cse/alisaliu/miniconda3/envs/nli/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('white')\n",
    "sns.set_palette('muted')\n",
    "red = sns.color_palette('muted')[3]\n",
    "green = sns.color_palette('muted')[2]\n",
    "gray = sns.color_palette('muted')[-3]\n",
    "\n",
    "premise = 'Donald Trump even said, on his very first day in office, he would require every school in America to let people carry guns into our classrooms.'\n",
    "hypothesis = \"Donald Trump said on his first day in office that every school in America would have to allow people to carry guns in classrooms.\"\n",
    "probs = predict_nli(premise, hypothesis, multilabel_model, tokenizer)\n",
    "print(probs)\n",
    "x = list(probs.values())\n",
    "fig, ax = plt.subplots(figsize=(4,2))\n",
    "sns.barplot(x, NLI_LABELS, order=['entailment', 'neutral', 'contradiction'], palette=[green, gray, red])\n",
    "ax.set_xlim(right=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/multilabel_pred.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab2dce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
