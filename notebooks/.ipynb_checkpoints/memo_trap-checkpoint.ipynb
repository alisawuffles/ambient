{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79df0c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/xlab/alisaliu/ambient\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'ambient':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c954d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from generation.gpt3_generation import request\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6483643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for part in range(4):\n",
    "    df = pd.read_csv(f'../memo-traps/data/memo-trap/memo-trap-PART{part+1}.csv')\n",
    "    df['part'] = part\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b4b3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memo_trap = pd.concat(dfs)\n",
    "memo_trap['classes'] = [ast.literal_eval(c) for c in memo_trap.classes]\n",
    "memo_trap['classes'] = [[o.replace('.','').strip() for o in c] for c in memo_trap.classes]\n",
    "memo_trap['prompt'] = [p.replace('Write a quote that ends in', 'Continue the sentence directly with') for p in memo_trap.prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ef8440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 80/2539 [00:59<13:10,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 129d68af1bcb4bdd52de15683a13a1ad in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 85/2539 [01:31<1:43:12,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d0102beeb494a884de9a17409ba52d13 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 139/2539 [02:22<12:30,  3.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d3e9c25c4ad598c6b36689ab9de32b62 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 256/2539 [03:34<13:23,  2.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e0dbdf14ea009c2926a861e3ea6b8cea in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 429/2539 [05:13<15:12,  2.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 267f27f11849958d294be3b499b6219a in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 449/2539 [05:52<19:31,  1.78it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f074fd92e695bff77a97f7f0a3593317 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 563/2539 [07:04<10:51,  3.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8cdd7d0378c829e243f5216838050cfb in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 598/2539 [07:47<10:05,  3.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0082abe3758d8da330b38a12b3a3b3e8 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 614/2539 [08:23<13:40,  2.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ead7ebd690b547fdf732cbe2e08b7f20 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 643/2539 [09:05<10:25,  3.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 411f4984aa58b43801072a38740568d3 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 778/2539 [10:26<12:07,  2.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d3e8f7f91c22f77afdcf3dfae1b2bc76 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 941/2539 [12:05<09:24,  2.83it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b90b5e2a0b8e6ca03ec5037938b7608a in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 967/2539 [12:46<11:14,  2.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1aa822efafb659bfc74a18071c488e0f in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 990/2539 [13:25<09:40,  2.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3e0b540b83d75452aa60cb0be6e55832 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1040/2539 [14:14<08:39,  2.89it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8c10848d80386d325b088dc27521e07d in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1118/2539 [15:18<08:42,  2.72it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 99293ce31e6e514aa89ab214289438ef in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1186/2539 [16:15<09:52,  2.29it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 856e0f0d30bf5de9ddf9c25899b583db in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1222/2539 [17:00<09:32,  2.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8522a369eeb598205fea89fc75b65c80 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1355/2539 [18:28<06:44,  2.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 38d7cd83db4347d4ef4bb77bfcfc8dcb in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1411/2539 [19:20<06:23,  2.94it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 81e9c6132430fc39f445ab79388bd3d9 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1417/2539 [19:53<35:32,  1.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2c2b1b2a40594a40fb6ea2f953b8e7f7 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 1516/2539 [21:05<08:11,  2.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 677916848ffb91b95505894cc90c6214 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1539/2539 [21:45<07:26,  2.24it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ffe299500d2dbeba0148c8cff8edb1e8 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1576/2539 [22:31<09:26,  1.70it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0af5ce75bf5c136dba15410ed22013c0 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1707/2539 [23:57<05:08,  2.70it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 827f27a95a6ebd2a8331802d7431d597 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1792/2539 [25:02<05:24,  2.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eb9e48e18134e3b590d36e6618889fc2 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 2089/2539 [27:37<03:28,  2.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9f6682fe5c82e7330b77f36e51e0bb9a in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 2092/2539 [28:08<35:53,  4.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f714e4ff9f6ee667347f01ad5bd5ff86 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 2099/2539 [28:41<13:17,  1.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4c2517e6d7088713794c23b9fe1aacce in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 2141/2539 [29:31<03:26,  1.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ecd38fcb3e14323be41464fb981f28d9 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2242/2539 [30:46<01:44,  2.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 38e6c768fd663f32ff453db4f3aaebe2 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 2272/2539 [31:28<01:33,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 85029346a6d1c080d557aa601ed2de92 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 2353/2539 [32:33<01:01,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1b5668b96166e2d031a1fb288d487938 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 2379/2539 [33:14<01:16,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f77351564966ea074d48bc2d14124705 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 2403/2539 [33:55<01:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID faa890ffb7c681ce4765623931be6fb5 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 2461/2539 [34:49<00:31,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fd77312857d9e3b52d316fc697f3cac7 in your message.)\n",
      "Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2539/2539 [35:23<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i, row in tqdm(memo_trap.iterrows(), total=len(memo_trap.index)):\n",
    "    next_token = request(\n",
    "        messages=[{'role': 'user', 'content': row['prompt']}],\n",
    "        model='gpt-4',\n",
    "        max_tokens=1,\n",
    "        return_only_text=True,\n",
    "        temperature=0,\n",
    "    )\n",
    "    res = {\n",
    "        'prompt': row['prompt'],\n",
    "        'pred_next_token': next_token,\n",
    "        'true_next_token': row['classes'][row['answer_index']]\n",
    "    }\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a3c51ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results)\n",
    "result_df['correct'] = [res['pred_next_token'] in res['true_next_token'] for res in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56a27ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_json('../memo-traps/results/gpt4-results-04-20.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b5af9ac1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': \"What was the common belief prior to the following event: Alfred Lothat Wegener postulated that the Earth's continents have moved over geologic time relative to each other.\\nA. Earth's continents have always been stationary.\\nB. Earth's continents have moved relative to each other.\\nAnswer:\",\n",
       " 'pred_next_token': 'A',\n",
       " 'true_next_token': 'A',\n",
       " 'correct': True}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sample(1).iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cfca9613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7554155179204411"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "01e24598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1918\n",
       "False     621\n",
       "Name: correct, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['correct'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5b0faacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7209302325581395"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.loc[result_df['prompt'].str.contains('Continue the quote directly')].correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a4a40251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.608540925266904"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.loc[result_df['prompt'].str.contains('Translate')].correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a601c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.loc[result_df['prompt'].str.contains('Translate')].correct.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
