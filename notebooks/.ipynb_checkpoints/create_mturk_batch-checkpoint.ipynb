{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abbfc6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/xlab/alisaliu/ambignli\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'ambignli':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fbbe8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from modeling.multitask_model import RobertaForMultitaskSequenceClassification\n",
    "from utils.utils import predict_nli\n",
    "from torch import sigmoid\n",
    "from collections import Counter\n",
    "from utils.utils import ensure_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ec577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nli(premise, hypothesis, model, tokenizer):\n",
    "    x = tokenizer(premise, hypothesis, return_tensors='pt', max_length=128, truncation=True).to('cuda')\n",
    "    logits = model(**x).logits\n",
    "    # multi-task model\n",
    "    if hasattr(model, 'output_heads'):\n",
    "        probs = logits.softmax(dim=-1).squeeze(0)\n",
    "        return {model.config.id2label[i]: probs[i,1].item() for i in range(len(probs))}\n",
    "    # multi-label model\n",
    "    elif model.config.problem_type == 'multi_label_classification':\n",
    "        logits = logits.squeeze(0)\n",
    "        probs = sigmoid(logits)\n",
    "        return {model.config.id2label[i]: probs[i].item() for i in range(len(probs))}\n",
    "    # classification model\n",
    "    else:\n",
    "        probs = logits.softmax(dim=1).squeeze(0)\n",
    "        return {model.config.id2label[i]: probs[i].item() for i in range(len(probs))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df1490bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_model = RobertaForSequenceClassification.from_pretrained('models/roberta-large-wanli-multilabel').to('cuda')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('models/roberta-large-wanli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca847de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_example_ambiguity(df):\n",
    "    df['ambiguity_score'] = None\n",
    "    df['predicted_labels'] = None\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df.index)):\n",
    "        premise, hypothesis = row['premise'], row['hypothesis']\n",
    "        probs = predict_nli(premise, hypothesis, multilabel_model, tokenizer)\n",
    "        preds = set([l for l, p in probs.items() if p > 0.04])\n",
    "        # ambiguity score is the probability assigned to the second-highest label\n",
    "        sorted_probs = sorted([p for p in probs.values()], reverse=True)\n",
    "        s = sorted_probs[1]\n",
    "        df.at[i, 'ambiguity_score'] = s\n",
    "        df.at[i, 'predicted_labels'] = ', '.join(sorted(preds))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921cb583",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dir = Path('generated_data/wanli_disagreement_p0.9_davinci-002')\n",
    "df_wanli_disagreement_instruct = pd.read_json(gen_dir / 'filtered_examples.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac77a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 30938/77870 [07:40<11:23, 68.67it/s]"
     ]
    }
   ],
   "source": [
    "df = compute_example_ambiguity(df_wanli_disagreement_instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44964b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>nearest_neighbors</th>\n",
       "      <th>ambiguity_score</th>\n",
       "      <th>predicted_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The proposal was met with some skepticism from...</td>\n",
       "      <td>The proposal was met with some optimism from t...</td>\n",
       "      <td>[82936, 245722, 331487, 19994]</td>\n",
       "      <td>0.925016</td>\n",
       "      <td>contradiction, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The company's decision to downsize was met wit...</td>\n",
       "      <td>The company's decision to downsize was met wit...</td>\n",
       "      <td>[82936, 245722, 331487, 19994]</td>\n",
       "      <td>0.886042</td>\n",
       "      <td>contradiction, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The amount of money that was spent on the proj...</td>\n",
       "      <td>The amount of money that was saved on the proj...</td>\n",
       "      <td>[82936, 245722, 331487, 19994]</td>\n",
       "      <td>0.630185</td>\n",
       "      <td>contradiction, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>We cannot be sure that the meeting will be pro...</td>\n",
       "      <td>We cannot be sure that the meeting will not be...</td>\n",
       "      <td>[82936, 245722, 331487, 19994]</td>\n",
       "      <td>0.126387</td>\n",
       "      <td>contradiction, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The company will only offer the position to so...</td>\n",
       "      <td>The company will only offer the position to so...</td>\n",
       "      <td>[214335, 8249, 65040, 102411]</td>\n",
       "      <td>0.791046</td>\n",
       "      <td>entailment, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77863</th>\n",
       "      <td>104063</td>\n",
       "      <td>Most people in the United States speak English.</td>\n",
       "      <td>English is the official language of the United...</td>\n",
       "      <td>[22805, 173022, 66665, 188215]</td>\n",
       "      <td>0.747514</td>\n",
       "      <td>entailment, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77864</th>\n",
       "      <td>104064</td>\n",
       "      <td>The novel is a fiction.</td>\n",
       "      <td>The movie is based on a true story.</td>\n",
       "      <td>[22805, 173022, 66665, 188215]</td>\n",
       "      <td>0.662432</td>\n",
       "      <td>contradiction, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77865</th>\n",
       "      <td>104065</td>\n",
       "      <td>The poet T.S. Eliot wrote, \"We shall not cease...</td>\n",
       "      <td>We never really know a place until we leave it.</td>\n",
       "      <td>[22805, 173022, 66665, 188215]</td>\n",
       "      <td>0.066416</td>\n",
       "      <td>contradiction, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77867</th>\n",
       "      <td>104067</td>\n",
       "      <td>The researchers say that this is the first stu...</td>\n",
       "      <td>This is the first study to look at the long-te...</td>\n",
       "      <td>[133594, 371112, 155042, 348420]</td>\n",
       "      <td>0.744364</td>\n",
       "      <td>entailment, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77868</th>\n",
       "      <td>104068</td>\n",
       "      <td>In a recent study, researchers found that peop...</td>\n",
       "      <td>Coffee is good for you.</td>\n",
       "      <td>[133594, 371112, 155042, 348420]</td>\n",
       "      <td>0.781466</td>\n",
       "      <td>entailment, neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35984 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                            premise  \\\n",
       "0           0  The proposal was met with some skepticism from...   \n",
       "1           2  The company's decision to downsize was met wit...   \n",
       "2           3  The amount of money that was spent on the proj...   \n",
       "3           4  We cannot be sure that the meeting will be pro...   \n",
       "4           5  The company will only offer the position to so...   \n",
       "...       ...                                                ...   \n",
       "77863  104063    Most people in the United States speak English.   \n",
       "77864  104064                            The novel is a fiction.   \n",
       "77865  104065  The poet T.S. Eliot wrote, \"We shall not cease...   \n",
       "77867  104067  The researchers say that this is the first stu...   \n",
       "77868  104068  In a recent study, researchers found that peop...   \n",
       "\n",
       "                                              hypothesis  \\\n",
       "0      The proposal was met with some optimism from t...   \n",
       "1      The company's decision to downsize was met wit...   \n",
       "2      The amount of money that was saved on the proj...   \n",
       "3      We cannot be sure that the meeting will not be...   \n",
       "4      The company will only offer the position to so...   \n",
       "...                                                  ...   \n",
       "77863  English is the official language of the United...   \n",
       "77864                The movie is based on a true story.   \n",
       "77865    We never really know a place until we leave it.   \n",
       "77867  This is the first study to look at the long-te...   \n",
       "77868                            Coffee is good for you.   \n",
       "\n",
       "                      nearest_neighbors ambiguity_score  \\\n",
       "0        [82936, 245722, 331487, 19994]        0.925016   \n",
       "1        [82936, 245722, 331487, 19994]        0.886042   \n",
       "2        [82936, 245722, 331487, 19994]        0.630185   \n",
       "3        [82936, 245722, 331487, 19994]        0.126387   \n",
       "4         [214335, 8249, 65040, 102411]        0.791046   \n",
       "...                                 ...             ...   \n",
       "77863    [22805, 173022, 66665, 188215]        0.747514   \n",
       "77864    [22805, 173022, 66665, 188215]        0.662432   \n",
       "77865    [22805, 173022, 66665, 188215]        0.066416   \n",
       "77867  [133594, 371112, 155042, 348420]        0.744364   \n",
       "77868  [133594, 371112, 155042, 348420]        0.781466   \n",
       "\n",
       "             predicted_labels  \n",
       "0      contradiction, neutral  \n",
       "1      contradiction, neutral  \n",
       "2      contradiction, neutral  \n",
       "3      contradiction, neutral  \n",
       "4         entailment, neutral  \n",
       "...                       ...  \n",
       "77863     entailment, neutral  \n",
       "77864  contradiction, neutral  \n",
       "77865  contradiction, neutral  \n",
       "77867     entailment, neutral  \n",
       "77868     entailment, neutral  \n",
       "\n",
       "[35984 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thres = 0.05\n",
    "sub_df = df.loc[df['ambiguity_score'] > thres]\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8813643",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_balanced_df = pd.read_json(gen_dir / 'balanced_examples_old.jsonl', lines=True)\n",
    "old_ids = old_balanced_df.id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d78824fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96325/2767759436.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  past_df = sub_df.loc[sub_df['id'].isin(old_ids)][~con_mask][ent_mask]\n",
      "/tmp/ipykernel_96325/2767759436.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  balanced_df = pd.concat([balanced_df, sub_df.loc[~sub_df['id'].isin(old_ids)][~con_mask][ent_mask].sample(num_entailment_needed-len(past_df))])\n"
     ]
    }
   ],
   "source": [
    "# include all examples with contradiction label\n",
    "con_mask = sub_df['predicted_labels'].str.contains('contradiction')\n",
    "balanced_df = sub_df[con_mask]\n",
    "# get label distribution\n",
    "counter = [ls.split(', ') for ls in balanced_df.predicted_labels.tolist()]\n",
    "counter = Counter([l for ls in counter for l in ls])\n",
    "# patch up with entailment examples\n",
    "num_entailment_needed = counter['contradiction'] - counter['entailment']\n",
    "ent_mask = sub_df['predicted_labels'].str.contains('entailment')\n",
    "# balanced_df = pd.concat([balanced_df, sub_df[~con_mask][ent_mask].sample(num_entailment_needed)])\n",
    "# use examples from previous data\n",
    "past_df = sub_df.loc[sub_df['id'].isin(old_ids)][~con_mask][ent_mask]\n",
    "balanced_df = pd.concat([balanced_df, past_df])\n",
    "balanced_df = pd.concat([balanced_df, sub_df.loc[~sub_df['id'].isin(old_ids)][~con_mask][ent_mask].sample(num_entailment_needed-len(past_df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8e400a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contradiction, neutral                6864\n",
       "entailment, neutral                   6864\n",
       "contradiction, entailment, neutral    2621\n",
       "contradiction, entailment              602\n",
       "Name: predicted_labels, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.predicted_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40243e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16860\n",
      "16974\n"
     ]
    }
   ],
   "source": [
    "print(len(set(balanced_df.id.tolist()).intersection(set(old_ids))))\n",
    "print(len(set(old_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a552c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.sample(frac=1).to_csv('annotation/balanced_examples.csv', index=False)\n",
    "balanced_df.sample(frac=1).to_json(gen_dir / 'balanced_examples.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6143aae",
   "metadata": {},
   "source": [
    "## create new batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecda64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = pd.read_csv('annotation/ambignli/balanced_examples.csv')\n",
    "annotated_ids = pd.read_json('annotation/ambignli/annotated_examples.jsonl', lines=True)['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a3d6e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15495\n"
     ]
    }
   ],
   "source": [
    "# TODO: this may re-sample examples that were discarded\n",
    "batch_size = 100\n",
    "remaining_pool_df = balanced_df[~balanced_df.id.isin(annotated_ids)]\n",
    "print(len(remaining_pool_df))\n",
    "ensure_dir('annotation/batches/nextbatch')\n",
    "remaining_pool_df.sample(batch_size).to_csv('annotation/batches/nextbatch/examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2836e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
