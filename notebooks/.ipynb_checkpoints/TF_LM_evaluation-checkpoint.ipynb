{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e4be12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/xlab/alisaliu/ambient\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'ambient':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9091353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from generation.gpt3_generation import request\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c12139f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    'This may mean:': True,\n",
    "    'This does not necessarily mean:': True,\n",
    "    'This cannot mean:': False,\n",
    "    'This can only mean:': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a886cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambient_df = pd.read_json('annotation/AmbiEnt/validated_examples.jsonl', lines=True)\n",
    "test_df = ambient_df[ambient_df['premise_ambiguous'] ^ ambient_df['hypothesis_ambiguous']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c75ac3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3456it [00:19, 175.77it/s]                          \n"
     ]
    }
   ],
   "source": [
    "T_token = ' True'\n",
    "F_token = ' False'\n",
    "engine = 'text-davinci-003'\n",
    "score = 0\n",
    "tot_valid = 0\n",
    "batch_size = 128\n",
    "\n",
    "prompts = []\n",
    "answer_key = []\n",
    "template_ids = []\n",
    "for i, row in test_df.iterrows():\n",
    "    for sentence_key in ['premise', 'hypothesis']:\n",
    "        if row[f'{sentence_key}_ambiguous']:\n",
    "            disambiguations = [l[sentence_key] for l in row['disambiguations']]\n",
    "            \n",
    "            for disambiguation in disambiguations:\n",
    "                for template_id, (template, answer) in enumerate(templates.items()):\n",
    "                    prompts.append(f\"{row[sentence_key]} {template} {disambiguation} True or False?\\nAnswer:\")\n",
    "                    answer_key.append(answer)\n",
    "                    template_ids.append(template_id)\n",
    "\n",
    "assert len(prompts) == len(answer_key)\n",
    "\n",
    "inputs = prompts\n",
    "outputs = []\n",
    "with tqdm(total=len(prompts)) as pbar:\n",
    "    while len(inputs) > 0:\n",
    "        result = request(\n",
    "            prompt=inputs[:batch_size],\n",
    "            model=engine,\n",
    "            max_tokens=1,\n",
    "            logprobs=100,\n",
    "            temperature=0,\n",
    "            logit_bias={\"50256\": -100}    # prevent <|endoftext|> from being generated\n",
    "        )\n",
    "        outputs += result['choices']\n",
    "        inputs = inputs[batch_size:]\n",
    "        pbar.update(batch_size)\n",
    "\n",
    "        \n",
    "results = []\n",
    "stop_ct = 0\n",
    "no_prob_mass_ct = 0\n",
    "for prompt, template_id, output, answer in zip(prompts, template_ids, outputs, answer_key):\n",
    "    logprobs = output['logprobs']['top_logprobs'][0]\n",
    "    \n",
    "    if T_token in logprobs and F_token in logprobs:\n",
    "        tot_valid += 1\n",
    "\n",
    "        if logprobs[T_token] > logprobs[F_token]:\n",
    "            pred = True\n",
    "        else:\n",
    "            pred = False\n",
    "\n",
    "        if pred == answer:\n",
    "            score += 1\n",
    "\n",
    "        results.append({\n",
    "            'example_id': row['id'],\n",
    "            'template_id': template_id,\n",
    "            'prompt': prompt,\n",
    "            'prediction': pred,\n",
    "            'answer': answer,\n",
    "        })\n",
    "    else:\n",
    "        no_prob_mass_ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "082273f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45202622169249107"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score/tot_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf6e3842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a64faaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_json(f'results/TF_evaluation/{engine}.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "661d97b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b06c5710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3356"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5432c681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3356"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f4999d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uh oh\n"
     ]
    }
   ],
   "source": [
    "for i, out in enumerate(outputs):\n",
    "    if not out['logprobs']['top_logprobs']:\n",
    "        print('uh oh')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58dc7512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x145817142d60> JSON: {\n",
       "  \"finish_reason\": \"stop\",\n",
       "  \"index\": 37,\n",
       "  \"logprobs\": {\n",
       "    \"text_offset\": [],\n",
       "    \"token_logprobs\": [],\n",
       "    \"tokens\": [],\n",
       "    \"top_logprobs\": []\n",
       "  },\n",
       "  \"text\": \"\"\n",
       "}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28141c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
