{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fa5cf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/xlab/alisaliu/ambient\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'ambient':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f6dbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from utils.utils import predict_nli\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from utils.constants import label2id, NLI_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c55c4d",
   "metadata": {},
   "source": [
    "## imppres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e48c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('data/imppres')\n",
    "dfs = []\n",
    "for filename in os.listdir(data_dir / 'raw/implicature'):\n",
    "    if filename.endswith('.jsonl'):\n",
    "        dfs.append(pd.read_json(data_dir / 'raw/implicature' / filename, lines=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ed8a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "implicature = pd.concat(dfs)\n",
    "implicature = implicature.loc[implicature['gold_label_log'] != implicature['gold_label_prag']]\n",
    "implicature = implicature.rename({'sentence1': 'premise', 'sentence2': 'hypothesis'}, axis=1).drop(columns=['item_type', 'lexemes', 'spec_relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8381687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "implicature.to_json(data_dir / 'examples.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a34b05",
   "metadata": {},
   "source": [
    "## chaos NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f1aa519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('data/chaosNLI')\n",
    "chaos_nli = pd.read_json(data_dir / 'raw/chaosNLI_mnli_m.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "180530f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for i, row in chaos_nli.iterrows():\n",
    "    examples.append({\n",
    "        'premise': row['example']['premise'],\n",
    "        'hypothesis': row['example']['hypothesis'],\n",
    "        'label_counter': row['label_counter'],\n",
    "        'entropy': row['entropy']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6535667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(examples).to_json(data_dir / 'mnli_m.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f7f56",
   "metadata": {},
   "source": [
    "## uncertain NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65cc0915",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 'contradiction', 1: 'neutral', 2: 'entailment'}\n",
    "splits = ['train', 'dev', 'test']\n",
    "for split in splits:\n",
    "    df = pd.read_csv(f'data/unli/raw/{split}.csv')\n",
    "    df = df.replace({'nli': label_map})\n",
    "    df = df.rename({'pre': 'premise', 'hyp': 'hypothesis', 'nli': 'nli_label', 'unli': 'gold'}, axis=1)\n",
    "    df.to_json(f'data/unli/{split}.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eeb2c13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 785 rows\n"
     ]
    }
   ],
   "source": [
    "snli_train = pd.read_json('data/snli/train.jsonl', lines=True)\n",
    "\"\"\"\n",
    "surrogate function T → [0, 1] that maps SNLI categorical labels {ENT, NEU, CON} \n",
    "to the average score of all u-SNLI training annotations labeled with t in SNLI\n",
    "\n",
    "s: {ENT → 0.9272; NEU → 0.4250; CON → 0.0209}\n",
    "\"\"\"\n",
    "surrogate_function = {'entailment': 0.9272, 'neutral': 0.4250, 'contradiction': 0.0209}\n",
    "\n",
    "snli_train = snli_train.drop('genre', axis=1)\n",
    "snli_train = snli_train.replace({'gold': surrogate_function})\n",
    "print(f\"Dropping {len(snli_train[snli_train['gold'] == '-'])} rows\")\n",
    "snli_train = snli_train[snli_train['gold'] != '-']\n",
    "snli_train.to_json('data/unli/snli_regression.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6030041c",
   "metadata": {},
   "source": [
    "## AmbiNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "853c0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SMNLI dataset for pretraining\n",
    "\n",
    "dfs = []\n",
    "for dataset in ['mnli', 'snli']:\n",
    "    df = pd.read_json(f'data/{dataset}/train.jsonl', lines=True)\n",
    "    df = df[df['gold'] != '-']\n",
    "    df['dist_gold'] = None\n",
    "    for i, row in df.iterrows():\n",
    "        idx = label2id[row['gold']]\n",
    "        dist_label = [0] * len(NLI_LABELS)\n",
    "        dist_label[idx] = 1.0\n",
    "        df.at[i, 'dist_gold'] = dist_label\n",
    "    df = df.drop('gold', axis=1).rename({'dist_gold': 'gold'}, axis=1)\n",
    "    dfs.append(df)\n",
    "\n",
    "smnli = pd.concat(dfs)\n",
    "smnli.to_json('data/ambinli/smnli.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0dac6fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create AmbiNLI\n",
    "\n",
    "dfs = []\n",
    "for dataset in ['snli', 'mnli', 'unli']:\n",
    "    df = pd.read_json(f'data/ambinli/raw/ambi-{dataset}.jsonl', lines=True)\n",
    "    if dataset in ['snli', 'mnli']:\n",
    "        df = df[['sentence1', 'sentence2', 'index', 'label']]\n",
    "    else:\n",
    "        df = df[['pre', 'hyp', 'id', 'label']]\n",
    "    df = df.rename({'sentence1': 'premise', 'sentence2': 'hypothesis', 'pre': 'premise', 'hyp': 'hypothesis', 'label': 'gold', 'index': 'id'}, axis=1)\n",
    "    df['gold'] = [[g[2], g[0], g[1]] for g in df['gold']] # label order in original data: [entailment, neutral, contradiction]\n",
    "    df.to_json(f'data/ambinli/ambi-{dataset}.jsonl', lines=True, orient='records')\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7f18cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambinli = pd.concat(dfs)\n",
    "ambinli.to_json('data/ambinli/ambinli.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc67b815",
   "metadata": {},
   "source": [
    "## distilled SMNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04c11aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/distilled-smnli/relabel_s0.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26c8b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df.index\n",
    "df = df.rename({'sentence1': 'premise', 'sentence2': 'hypothesis'}, axis=1)\n",
    "df['gold'] = [[g[2], g[0], g[1]] for g in df['label_dist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d9f1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['premise', 'hypothesis', 'gold', 'id']].to_json('data/distilled-smnli/relabeled0.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b67dadb",
   "metadata": {},
   "source": [
    "## multi-label data from Jiang & de Marneffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f48eb04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'dev'\n",
    "df = pd.read_json(f'data/taxonomy/raw/{split}.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72828f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_to_label = {lab[0]: lab for lab in NLI_LABELS}\n",
    "label_map = {lab:', '.join([letter_to_label[l] for l in lab]) for lab in df.gold_label.value_counts().keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff633597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({'gold_label': label_map})\n",
    "df = df.rename(columns={'index': 'id', 'gold_label': 'gold'}).drop(['u_index', 'uid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36bd8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(f'data/taxonomy/{split}.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a21a392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
